[{"Authors":"Yi Y.K.; Zhang Y.; Myung J.","Author full names":"Yi, Yun Kyu (7202372766); Zhang, Yahan (57203830210); Myung, Junyoung (57217309475)","Author(s) ID":"7202372766; 57203830210; 57217309475","Title":"House style recognition using deep convolutional neural network","Year":2020,"Source title":"Automation in Construction","Volume":"118","Issue":null,"Art. No.":"103307","Page start":null,"Page end":null,"Page count":null,"Cited by":44,"DOI":"10.1016\/j.autcon.2020.103307","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85087091465&doi=10.1016%2fj.autcon.2020.103307&partnerID=40&md5=de265b324ebecaa39e74443306e52c5d","Abstract":"The recent development in deep learning has opened up a new era of possibilities, once difficult to achieve with conventional methods, to revolutionize image recognition, speech recognition, and natural language processing. Specifically, image recognition has been widely applied in various areas such as face recognition, object identification for security, and other purposes. Although it is rarely applied to discover new methods for use in architecture, image recognition has great potential in architectural design. For example, it can be used to identify the preference of the client and to design a building that satisfies a client's aesthetic preference. One of the major hurdles of utilizing image recognition in architecture is the architectural styles based on culture, location, and time. For that reason, it is difficult to identify an architectural style by non-trained clients and sometimes certain buildings are composed of different styles that are difficult to identify by experts as one style. This paper explores the possibility of using state-of-the-art image recognition algorithms in house style recognition to find out its limitations and possibilities. Moreover, the paper adopted a convolutional neural network model for classifying house styles in the US. Although the final accuracy is not high due to the lack of image datasets, the trained model performed reasonable predictions with a limited test set. The results show the importance of properly defining style for image recognition to improve its accuracy. © 2020 Elsevier B.V.","Author Keywords":"Deep Convolutional Neural Network (DCNN); Deep learning; House style; Image recognition","Index Keywords":"Architectural design; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image enhancement; Image recognition; Natural language processing systems; Network architecture; Sanitary sewers; Speech recognition; Aesthetic preference; Architectural style; Conventional methods; Image datasets; NAtural language processing; Object identification; Recognition algorithm; State of the art; Face recognition","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85087091465"},{"Authors":"Girard N.; Larrosa C.; Mapurisa W.; Trastour F.; Tarabalka Y.","Author full names":"Girard, Nicolas (57202915818); Larrosa, Cedric (58738459800); Mapurisa, Willard (57202621159); Trastour, Frederic (57211635936); Tarabalka, Yuliya (24512498300)","Author(s) ID":"57202915818; 58738459800; 57202621159; 57211635936; 24512498300","Title":"Brightearth City Texturing : Faithful Procedural 3d Urban Modeling From Satellite and Ground Imagery","Year":2023,"Source title":"International Geoscience and Remote Sensing Symposium (IGARSS)","Volume":"2023-July","Issue":null,"Art. No.":null,"Page start":5599.0,"Page end":5602.0,"Page count":3.0,"Cited by":1,"DOI":"10.1109\/IGARSS52108.2023.10282555","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85178336467&doi=10.1109%2fIGARSS52108.2023.10282555&partnerID=40&md5=97e6b60e9bf6e5b2d96d92552b2946ef","Abstract":"BrightEarth City Texturing is an automatic and resource-efficient 3D urban modeling pipeline, producing quality low-poly 3D models with high-resolution seamless textures suitable for real-time rendering. From a single satellite image it extracts building geometry with footprint polygons along with attributes such as building height, roof shape, and roof texture. If ground images are available it can also faithfully texture facades in terms of architectural style. © 2023 IEEE.","Author Keywords":"deep learning; digital twin; procedural; urban 3D modeling","Index Keywords":null,"Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85178336467"},{"Authors":"Zhang X.; Li S.; Chen C.","Author full names":"Zhang, Xiaoxia (57219538029); Li, Shaodan (56654516800); Chen, Changyao (59463797700)","Author(s) ID":"57219538029; 56654516800; 59463797700","Title":"Classification of architectural styles in Chinese traditional settlements using remote sensing images and building facade pictures","Year":2024,"Source title":"Journal of Geographical Sciences","Volume":"34","Issue":"12","Art. No.":null,"Page start":2457.0,"Page end":2476.0,"Page count":19.0,"Cited by":0,"DOI":"10.1007\/s11442-024-2300-5","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85211352369&doi=10.1007%2fs11442-024-2300-5&partnerID=40&md5=d4e4d6876b5c3fc1ecf005595347deb3","Abstract":"The classification of Chinese traditional settlements (CTSs) is extremely important for their differentiated development and protection. The innovative double-branch classification model developed in this study comprehensively utilized the features of remote sensing (RS) images and building facade pictures (BFPs). This approach was able to overcome the limitations of previous methods that used only building facade images to classify settlements. First, the features of the roofs and walls were extracted using a double-branch structure, which consisted of an RS image branch and BFP branch. Then, a feature fusion module was designed to fuse the features of the roofs and walls. The precision, recall, and F1-score of the proposed model were improved by more than 4% compared with the classification model using only RS images or BFPs. The same three indexes of the proposed model were improved by more than 2% compared with other deep learning models. The results demonstrated that the proposed model performed well in the classification of architectural styles in CTSs. © Science Press 2024.","Author Keywords":"architectural style classification; building facade pictures; Chinese traditional settlements; convolutional neural network; remote sensing images","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85211352369"},{"Authors":"Chen W.; Miao L.; Gui J.; Wang Y.; Li Y.","Author full names":"Chen, Weiyi (58833587100); Miao, Lingjuan (7005303274); Gui, Jinchao (59169659300); Wang, Yuhao (58930859800); Li, Yiran (57219132334)","Author(s) ID":"58833587100; 7005303274; 59169659300; 58930859800; 57219132334","Title":"FLsM: Fuzzy Localization of Image Scenes Based on Large Models","Year":2024,"Source title":"Electronics (Switzerland)","Volume":"13","Issue":"11","Art. No.":"2106","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.3390\/electronics13112106","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85195794021&doi=10.3390%2felectronics13112106&partnerID=40&md5=cf783a5ae8aeb02bb29b4b1a252db2ca","Abstract":"This article primarily focuses on the study of image-based localization technology. While traditional methods have made significant advancements in technology and applications, the emerging field of visual image-based localization technology demonstrates tremendous potential for research. Deep learning has exhibited a strong performance in image processing, particularly in developing visual navigation and localization techniques using large-scale visual models. This paper introduces a sophisticated scene image localization technique based on large models in a vast spatial sample environment. The study involved training convolutional neural networks using millions of geographically labeled images, extracting image position information using large model algorithms, and collecting sample data under various conditions in elastic scene space. Through visual computation, the shooting position of photos was inferred to obtain the approximate position information of users. This method utilizes geographic location information to classify images and combines it with landmarks, natural features, and architectural styles to determine their locations. The experimental results show variations in positioning accuracy among different models, with the most optimal model obtained through training on a large-scale dataset. They also indicate that the positioning error in urban street-based images is relatively small, whereas the positioning effect in outdoor and local scenes, especially in large-scale spatial environments, is limited. This suggests that the location information of users can be effectively determined through the utilization of geographic data, to classify images and incorporate landmarks, natural features, and architectural styles. The study’s experimentation indicates the variation in positioning accuracy among different models, highlighting the significance of training on a large-scale dataset for optimal results. Furthermore, it highlights the contrasting impact on urban street-based images versus outdoor and local scenes in large-scale spatial environments. © 2024 by the authors.","Author Keywords":"deep learning; fuzzy localization; image processing; large models; localization of image scenes","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85195794021"},{"Authors":"Gao L.; Wu Y.; Yang T.; Zhang X.; Zeng Z.; Chan C.K.D.; Chen W.","Author full names":"Gao, Le (55681543600); Wu, Yanqing (58125174500); Yang, Tian (58836391400); Zhang, Xin (57918341900); Zeng, Zhiqiang (57211678095); Chan, Chak Kwan Dickson (7404814110); Chen, Weihui (58124887600)","Author(s) ID":"55681543600; 58125174500; 58836391400; 57918341900; 57211678095; 7404814110; 58124887600","Title":"Research on Image Classification and Retrieval Using Deep Learning with Attention Mechanism on Diaspora Chinese Architectural Heritage in Jiangmen, China","Year":2023,"Source title":"Buildings","Volume":"13","Issue":"2","Art. No.":"275","Page start":null,"Page end":null,"Page count":null,"Cited by":13,"DOI":"10.3390\/buildings13020275","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85149232343&doi=10.3390%2fbuildings13020275&partnerID=40&md5=743eee12c618538596c3da72db254d94","Abstract":"The study of the architectural heritage of the Chinese diaspora has an important role and significance in China’s historical and cultural background in the preservation of cultural data, the restoration of images, and in the analysis of human social and ideological conditions. The images from the architectural heritage of the Chinese diaspora usually include frescos, decorative patterns, chandelier base patterns, various architectural styles and other major types of architecture. Images of the architectural heritage of the Chinese diaspora in Jiangmen City, Guangdong Province, China are the research object of this study. A total of 5073 images of diaspora Chinese buildings in 64 villages and 16 towns were collected. In view of the fact that different types of image vary greatly in features while there are only small differences among the features of the same type of image, this study uses the depth learning method to design the Convolutional Neural Network Attention Retrieval Framework (CNNAR Framework). This approach can be divided into two stages. In the first stage, the transfer learning method is used to classify the image in question by transferring the trained parameters of the Paris500K datasets image source network to the target network for training, and thus the classified image is obtained. The advantage of this method is that it narrows the retrieval range of the target image. In the second stage, the fusion attention mechanism is used to extract the features of the images that have been classified, and the distance between similar images of the same type is reduced by loss of contrast. When we retrieve images, we can use the features extracted in the second stage to measure the similarities among them and return the retrieval results. The results show that the classification accuracy of the proposed method reaches 98.3% in the heritage image datasets of the JMI Chinese diaspora architectures. The mean Average Precision (mAP) of the proposed algorithm can reach 76.6%, which is better than several mainstream model algorithms. At the same time, the image results retrieved by the algorithm in this paper are very similar to those of the query image. In addition, the CNNAR retrieval framework proposed in this paper achieves accuracies of 71.8% and 72.5% on the public data sets Paris500K and Corel5K, respectively, which can be greatly generalized and can, therefore, also be effectively applied to other topics datasets. The JMI architectural heritage image database constructed in this study, which is rich in cultural connotations of diaspora Chinese homeland life, can provide strong and reliable data support for the follow-up study of the zeitgeist of the culture reflected in architecture and the integration of Chinese and Western aesthetics. At the same time, through the rapid identification, classification, and retrieval of precious architectural images stored in the database, similar target images can be retrieved reasonably and accurately; then, accurate techniques can be provided to restore old and damaged products of an architectural heritage. © 2023 by the authors.","Author Keywords":"architectural heritage; attention mechanism; deep learning; image classification; image retrieval","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85149232343"},{"Authors":null,"Author full names":null,"Author(s) ID":null,"Title":"6th International Conference on Dynamics of Information Systems, DIS 2023","Year":2024,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"14321 LNCS","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":249.0,"Cited by":0,"DOI":null,"Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85182012408&partnerID=40&md5=522c7ea6285ddafaf6576cff74900c74","Abstract":"The proceedings contain 18 papers. The special focus in this conference is on Dynamics of Information Systems. The topics include: Dispersion of Personal Spaces; an Evolutionary Approach to Automated Class-Specific Data Augmentation for Image Classification; augmented Lagrangian Method for Linear Programming Using Smooth Approximation; the Coherent Multi-representation Problem for Protein Structure Determination; the Effects of Shift Generation on Staff Rostering; consumers Financial Distress: Prediction and Prescription Using Machine Learning; optimizing Classroom Assignments to Reduce Non-essential Interactions Among University-Level Students During Pandemics; introducing a New Metric for Improving Trustworthiness in Real Time Object Detection; a Numerical Scheme for a Generalized Fractional Derivative with Variable Order; a Risk-Cost Analysis for an Increasingly Widespread Monitoring of Railway Lines; a Collaborative Multi-objective Approach for Clustering Task Based on Distance Measures and Clustering Validity Indices; iranian Architectural Styles Recognition Using Image Processing and Deep Learning; a Quasi-extreme Reduction for Interval Transportation Problems; assignment of Unexpected Tasks in Embedded System Design Process Using Genetic Programming; Improving Handwritten Cyrillic OCR by Font-Based Synthetic Text Generator; a Critical Node-Centric Approach to Enhancing Network Security.","Author Keywords":null,"Index Keywords":null,"Document Type":"Conference review","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85182012408"},{"Authors":"Li R.; Wang Y.; Liu Y.","Author full names":"Li, Rui (57192998134); Wang, Yaowu (57204333498); Liu, Yang (59107346100)","Author(s) ID":"57192998134; 57204333498; 59107346100","Title":"Study on the classification of building based on ResNet","Year":2023,"Source title":"Proceedings - 2023 11th International Conference on Information Systems and Computing Technology, ISCTech 2023","Volume":null,"Issue":null,"Art. No.":null,"Page start":458.0,"Page end":462.0,"Page count":4.0,"Cited by":0,"DOI":"10.1109\/ISCTech60480.2023.00089","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85186766168&doi=10.1109%2fISCTech60480.2023.00089&partnerID=40&md5=c517a7f58791a11441ac3c4d244ed3be","Abstract":"In real estate appraisal, the building conditions have a significant impact on the asset value. The condition of the building can be estimated based on the characteristics of the external wall materials, architectural style and appearance. Such estimates are complicated because images of buildings contain a lot of confusing information, including different angles and weather Now it is often based on the appraiser's experience, but this introduces too many human factors. Increasingly sophisticated artificial intelligence technology can help solve these problems and provide accurate and objective evaluation of buildings. For practical application, this paper divides buildings into three categories with different values according to their conditions. Then train the building images and verify the accuracy by ResNet-152 neural network. The experimental results show that ResNet-152 has a high accuracy and adaptability for building classification tasks.  © 2023 IEEE.","Author Keywords":"Building Values; Deep Learning; ResNet-152","Index Keywords":"Deep learning; Architectural style; Asset value; Building conditions; Building value; Condition; Deep learning; External walls; Real estate appraisals; Resnet-152; Wall materials; Buildings","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85186766168"},{"Authors":"Riyadi S.; Abidin F.A.; Audita N.","Author full names":"Riyadi, Slamet (6503991450); Abidin, Febriyanti Azahra (59294045500); Audita, Nia (59301801000)","Author(s) ID":"6503991450; 59294045500; 59301801000","Title":"Comparison of ResNet50V2 and MobileNetV2 Models in Building Architectural Style Classification","Year":2024,"Source title":"2024 International Conference on Intelligent Systems and Computer Vision, ISCV 2024","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":1,"DOI":"10.1109\/ISCV60512.2024.10620099","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85202355094&doi=10.1109%2fISCV60512.2024.10620099&partnerID=40&md5=5f08e8e9dda05ed61f7feac78ba4df30","Abstract":"Artificial intelligence and image processing methods are key in classifying architectural styles in this digital era. Previous research has demonstrated the success of Deep Learning (DL) and Convolutional Neural Network (CNN) techniques in classifying architectural styles, but variations in accuracy and challenges in dealing with variations in lighting, shooting angles, and complexity of architectural styles remain a concern. Through literature exploration, it was found that a direct comparison between the ResNet50V2 and MobileNetV2 models in the context of architectural style classification has never been carried out thoroughly. Disadvantages of existing methods include a better understanding of the model's ability to distinguish subtle nuances in architectural design. This research aims to compare the performance of ResNet50V2 and MobileNetV2 in architectural style classification. ResNet50V2 achieved 93% accuracy, while MobileNetV2 achieved 82%. Graphical analysis and evaluation metrics, including confusion matrices and classification reports, provide deep insight into their performance. In conclusion, ResNet50V2 and MobileNetV2 have their respective advantages and disadvantages. ResNet50V2 shows high and stable accuracy, while MobileNetV2 shows stability with certain fluctuations. Both models have the potential to be used in architectural style classification, but model selection must consider the specific needs and characteristics of the dataset. This research is expected to provide valuable guidance for developing more efficient and reliable classification methods in understanding and preserving building architectural styles. This research contribution is relevant to the industrial development trend, which increasingly relies on technology to increase efficiency and accuracy in various tasks. © 2024 IEEE.","Author Keywords":"Architectural Style Classification; Artificial Intelligence; Building Heritage; Classification Comparison; Deep Learning; MobileNetV2; Model Performance; ResNet50V2","Index Keywords":"Architectural design; Deep neural networks; Architectural style; Architectural style classification; Building heritage; Classification comparison; Deep learning; In-buildings; Mobilenetv2; Modeling performance; Performance; Resnet50v2; Convolutional neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85202355094"},{"Authors":"Sun H.; Xu H.; Wei Q.","Author full names":"Sun, Haozun (57903673000); Xu, Hong (57203983522); Wei, Quanfeng (58037458900)","Author(s) ID":"57903673000; 57203983522; 58037458900","Title":"The Classification Method of Urban Architectural Styles Based on Deep Learning and Street View Imagery","Year":2022,"Source title":"Advances in Transdisciplinary Engineering","Volume":"31","Issue":null,"Art. No.":null,"Page start":823.0,"Page end":830.0,"Page count":7.0,"Cited by":2,"DOI":"10.3233\/ATDE220940","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85145256022&doi=10.3233%2fATDE220940&partnerID=40&md5=ffa70c6811802606f84f566f44da4d25","Abstract":"The task of identifying urban architectural styles occupies a very necessary position in the fields of construction of smart cities, sustainable urban development and community regeneration. The research method proposed in this paper can improve on the inconveniences of traditional methods of identifying urban architectural styles, such as: the community building is relatively old, and the integration of more periods of architectural style can significantly affect the test results. It is an established fact that data cannot be collected and processed efficiently by humans alone, and can not enter such qualitative and descriptive research methods into the computer for auxiliary research. This paper is based on the explosion of information data use in the 21st century, and use deep learning technology to process unstructured data with convolutional neural networks as the core to assist in the identification of urban architectural styles. With the rapid development of deep learning technology in recent years, its classification techniques for identification of street images of urban buildings can be used for urban management, and a new strong underpinning for the allocation of urban resources, urban diversification management, and the transformation of old communities in the later period has been provided by the proper classification of urban architectural styles. Notwithstanding its restrictions, the approach presented in this research has shown promise and the valuable value of deep learning-based techniques for the study of architectural styles, and this approach has universal significance.  © 2022 The authors and IOS Press.","Author Keywords":"deep learning; Style recognition; urban planning","Index Keywords":"Architecture; Convolutional neural networks; Image classification; Learning systems; Transfer learning; Urban growth; Architectural style; Classification methods; Community buildings; Deep learning; Established facts; Learning technology; Research method; Style recognition; Sustainable urban development; Urban community; Deep learning","Document Type":"Conference paper","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85145256022"},{"Authors":"Li X.; Yang Y.; Sun C.; Fan Y.","Author full names":"Li, Xuan (56320025700); Yang, Yuanze (59382981500); Sun, Chuanwei (15763590900); Fan, Yong (57219250127)","Author(s) ID":"56320025700; 59382981500; 15763590900; 57219250127","Title":"Investigation, Evaluation, and Dynamic Monitoring of Traditional Chinese Village Buildings Based on Unmanned Aerial Vehicle Images and Deep Learning Methods","Year":2024,"Source title":"Sustainability (Switzerland)","Volume":"16","Issue":"20","Art. No.":"8954","Page start":null,"Page end":null,"Page count":null,"Cited by":2,"DOI":"10.3390\/su16208954","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85207335339&doi=10.3390%2fsu16208954&partnerID=40&md5=df06f70a11dc308e9367a571dc87e55a","Abstract":"The investigation, evaluation, and dynamic monitoring of traditional village buildings are crucial for the protection and inheritance of their architectural styles. This study takes traditional villages in Shandong Province, China, as an example, employing UAV images and deep learning technology. Utilizing the YOLOv8 instance segmentation model, it introduces three key features reflecting the condition of traditional village buildings: roof status, roof form, and courtyard vegetation coverage. By extracting feature data on the condition of traditional village buildings and constructing a transition matrix for building condition changes, combined with corresponding manual judgment assistance, the study classifies, counts, and visually outputs the conditions and changes of buildings. This approach enables the investigation, evaluation, and dynamic monitoring of traditional village buildings. The results show that deep learning technology significantly enhances the efficiency and accuracy of traditional village architectural investigation and evaluations, and it performs well in dynamic monitoring of building condition changes. The “UAV image + deep learning” technical system, with its simplicity, accuracy, efficiency, and low cost, can provide further data and technical support for the planning, protection supervision, and development strategy formulation of traditional Chinese villages. © 2024 by the authors.","Author Keywords":"architectural feature recognition; deep learning; dynamic monitoring; traditional Chinese village; UAV images","Index Keywords":"China; Shandong; architectural design; development strategy; machine learning; satellite imagery; segmentation; unmanned vehicle; vegetation cover; village","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85207335339"},{"Authors":"Darbandy M.T.; Zojaji B.; Sani F.A.","Author full names":"Darbandy, Mohammad Tayarani (57216459122); Zojaji, Benyamin (58805727000); Sani, Fariba Alizadeh (57414718300)","Author(s) ID":"57216459122; 58805727000; 57414718300","Title":"Iranian Architectural Styles Recognition Using Image Processing and Deep Learning","Year":2024,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"14321 LNCS","Issue":null,"Art. No.":null,"Page start":69.0,"Page end":82.0,"Page count":13.0,"Cited by":0,"DOI":"10.1007\/978-3-031-50320-7_5","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85181976688&doi=10.1007%2f978-3-031-50320-7_5&partnerID=40&md5=6177b6a882ebe1477157c3fdcc4a325a","Abstract":"Iranian architecture, also known as Persian architecture, encompasses the design of buildings in Iran and extends to various regions in West Asia, the Caucasus, and Central Asia. With a rich history dating back at least 5,000 BC, it boasts distinctive features and styles. Iran, located in the Middle East, has faced ongoing geopolitical challenges, including the potential for conflicts, such as those in Iraq and Afghanistan. Unfortunately, historical monuments often become unintentional casualties during wartime, suffering damage or destruction. These historical monuments hold cultural and historical significance not only for the country they belong to but for all of humanity. Therefore, it is crucial to make efforts to preserve them. In this paper, we propose the development of an automated system utilizing Deep Learning methods for the detection and recognition of historical monuments. This system can be integrated into military equipment to help identify the architectural style of a building and determine its construction date. By doing so, it can provide a critical warning to prevent the targeting of historically significant structures. To support our system, we have curated a dataset consisting of approximately 3,000 photographs showcasing six distinct styles of Iranian historical architecture. Figure 1 provides some examples of these photographs. It is worth noting that this dataset can be valuable for various scientific research projects and applications beyond our proposed system. Additionally, it offers tourists the opportunity to learn about Iranian historical monuments independently, using their mobile phones to access information about a monument’s historical period and architectural style, eliminating the need for a traditional guide. This initiative aims to safeguard the invaluable cultural heritage of Iran and neighboring regions, contributing to the collective preservation of these historical treasures. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Author Keywords":"Deep learning; Image classification; Image processing; Iranian architecture","Index Keywords":"Architecture; Automation; Computer architecture; Construction equipment; Deep learning; Historic preservation; Learning systems; Network architecture; Photography; Architectural style; Caucasus; Central Asia; Deep learning; Design of buildings; Historical monuments; Images classification; Images processing; Iranian architectures; Persians; Image classification","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85181976688"},{"Authors":"Wu Y.; Zhao P.; Zhou M.; Geng S.; Zhang D.","Author full names":"Wu, Yingbin (58565205400); Zhao, Peng (57221379168); Zhou, Mingquan (9332570500); Geng, Shengling (55265416400); Zhang, Dan (57204704473)","Author(s) ID":"58565205400; 57221379168; 9332570500; 55265416400; 57204704473","Title":"Building Edge Detection Technology from Remote Sensing Image Based on NSCT and Tensor Voting","Year":2024,"Source title":"Journal of Physics: Conference Series","Volume":"2759","Issue":"1","Art. No.":"012011","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1088\/1742-6596\/2759\/1\/012011","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85194173065&doi=10.1088%2f1742-6596%2f2759%2f1%2f012011&partnerID=40&md5=2795be8c702c95be244966c52a3e036c","Abstract":"An edge detection technology based on the combination of non-downsampling contour wave transform (NSCT) and tensor voting is proposed, which aims to obtain more accurate and detailed edge information of buildings in remote sensing images. Firstly, NSCT is used for image decomposition to obtain the subband frequency information of different scales and angles. Then, position encoding is performed on these subband coefficients to obtain second-order symmetric tensors at the corresponding positions. Tensors of different scales and angles at the same position are weighted and summed to complete feature fusion. Finally, the edge features of the image are obtained based on tensor voting theory. The experimental results show that compared to common edge detection technologies, such as Canny, Fast Edge (Fast edge detection using structured forests) and HED (Holistically-Nested Edge Detection), our method can more accurately and intensively reflect the boundaries of buildings and the edge information of roofs, providing better support for the analysis of building types and architectural styles. Compared to the HED method, which is based on deep learning, our method improves PSNR and SSIM metrics by 0.98 and 0.03, respectively.  © Published under licence by IOP Publishing Ltd.","Author Keywords":null,"Index Keywords":"Deep learning; Remote sensing; Tensors; Down sampling; Edge detection technology; Edge information; Frequency information; Image decomposition; Image-based; Remote sensing images; Subbands; Technology-based; Tensor voting; Edge detection","Document Type":"Conference paper","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85194173065"},{"Authors":"Xu H.; Sun H.; Wang L.; Yu X.; Li T.","Author full names":"Xu, Hong (57203983522); Sun, Haozun (57903673000); Wang, Lubin (57224113359); Yu, Xincan (58484665900); Li, Tianyue (57224901867)","Author(s) ID":"57203983522; 57903673000; 57224113359; 58484665900; 57224901867","Title":"Urban Architectural Style Recognition and Dataset Construction Method under Deep Learning of street View Images: A Case Study of Wuhan","Year":2023,"Source title":"ISPRS International Journal of Geo-Information","Volume":"12","Issue":"7","Art. No.":"264","Page start":null,"Page end":null,"Page count":null,"Cited by":14,"DOI":"10.3390\/ijgi12070264","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85166183971&doi=10.3390%2fijgi12070264&partnerID=40&md5=c4ceff37d4d4810d7a73dce56d3b8048","Abstract":"The visual quality and spatial distribution of architectural styles represent a city’s image, influence inhabitants’ living conditions, and may have positive or negative social consequences which are critical to urban sensing and designing. Conventional methods of identifying architectural styles rely on human labor and are frequently time-consuming, inefficient, and subjective in judgment. These issues significantly affect the large-scale management of urban architectural styles. Fortunately, deep learning models have robust feature expression abilities for images and have achieved highly competitive results in object detection in recent years. They provide a new approach to supporting traditional architectural style recognition. Therefore, this paper summarizes 22 architectural styles in a study area which could be used to define and describe urban architectural styles in most Chinese urban areas. Then, this paper introduced a Faster-RCNN general framework of architectural style classification with a VGG-16 backbone network, which is the first machine learning approach to identifying architectural styles in Chinese cities. Finally, this paper introduces an approach to constructing an urban architectural style dataset by mapping the identified architectural style through continuous street view imagery and vector map data from a top-down building contour map. The experimental results show that the architectural style dataset created had a precision of 57.8%, a recall rate of 80.91%, and an F1 score of 0.634. This dataset can, to a certain extent, reflect the geographical distribution characteristics of a wide variety of urban architectural styles. The proposed approach could support urban design to improve a city’s image. © 2023 by the authors.","Author Keywords":"architectural style recognition; construction method; dataset; deep learning; street view images","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85166183971"},{"Authors":"Iturburu L.; Liu X.; Zhang X.; Wogen B.E.; Villamizar J.N.; Dyke S.J.; Ramirez J.; Choi J.B.; Valencia G.; Alcocer S.M.","Author full names":"Iturburu, Lissette (57194636996); Liu, Xiaoyu (57203202952); Zhang, Xin (57356117900); Wogen, Benjamin E. (58246769400); Villamizar, Juan Nicolas (59047525000); Dyke, Shirley J. (7003706556); Ramirez, Julio (35448832700); Choi, Jongseong Brad (58757096200); Valencia, Gianella (59043632600); Alcocer, Sergio M. (6602361698)","Author(s) ID":"57194636996; 57203202952; 57356117900; 58246769400; 59047525000; 7003706556; 35448832700; 58757096200; 59043632600; 6602361698","Title":"Building pose detection for the characterization of reinforced concrete buildings","Year":2024,"Source title":"Structural Design of Tall and Special Buildings","Volume":"33","Issue":"13","Art. No.":"e2120","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1002\/tal.2120","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85192257650&doi=10.1002%2ftal.2120&partnerID=40&md5=6151d83e58834c420f13634b404e4d9e","Abstract":"The automated identification of building characteristics for seismic vulnerability remains a challenge for governments due to the high number of buildings in cities. The diverse architectural styles of these buildings complicate the automated identification of building information (e.g., number of stories, structural system, and material type). Deep learning techniques lose accuracy as they generalize information, while the visual contents of a building exhibit a considerable range and diversity. This study leverages the pose detection technique to tackle such issues by focusing on a common construction style: reinforced concrete buildings representing columns, beams, or floors on the façade. With an aim to enable the assessment of seismic vulnerability, the technique developed herein is conceived for buildings with up to six stories that are more likely to be moment-frame buildings. The AI-enabled proposed framework starts with collecting building images and categorizing those containing this specific building type. A bounding box detector is then used to isolate building facades, for the subsequent identification of the structural frame with the High-Resolution Network (HR-Net). For demonstration, we illustrate this technique by identifying the structural frame on concrete buildings with a sample dataset developed based on buildings found in Mexico City in a pre-earthquake event state. © 2024 John Wiley & Sons Ltd.","Author Keywords":"building inventories; computer vision; earthquakes; HR-net; pose detection; reinforced concrete buildings","Index Keywords":"Computer vision; Concrete buildings; Deep learning; Gesture recognition; Reinforced concrete; Structural frames; Architectural style; Automated identification; Building characteristics; Building inventory; HR-net; Material's type; Pose detection; Reinforced concrete buildings; Seismic vulnerability; Structural systems; Earthquakes","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85192257650"},{"Authors":"Rababaah A.R.; Rababah A.M.","Author full names":"Rababaah, Aaron Rasheed (22958029000); Rababah, Alaa Musa (59042912500)","Author(s) ID":"22958029000; 59042912500","Title":"Intelligent machine vision model for building architectural style classification based on deep learning","Year":2023,"Source title":"International Journal of Computer Applications in Technology","Volume":"70","Issue":"1","Art. No.":null,"Page start":11.0,"Page end":21.0,"Page count":10.0,"Cited by":4,"DOI":"10.1504\/IJCAT.2022.129893","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85153874123&doi=10.1504%2fIJCAT.2022.129893&partnerID=40&md5=40c14a15cc3cf5d3d295ece71ee732d4","Abstract":"This paper presents an intelligent model for building architectural style classification. Image classification of architectural style is challenging to traditional machine vision methods. The main challenge in these systems is the feature extraction phase as there are many visual features in these styles that need to be extracted, refined and optimised. All these operations are done at the researcher discretion in traditional Machine Learning (ML) models. The advancements of ML to Deep Learning (DL) made automation of all the challenging operations possible. We constructed a machine vision model based on DL to investigate the effectiveness of DL in the classification problem at hand. A publicly available annotated data set was utilised to train and validate the proposed model. The data set consists of more than 5000 images of eight different architectural styles. The experimental results showed that the proposed model is reliable as it produced a classification accuracy of 95.44%. Copyright © 2022 Inderscience Enterprises Ltd.","Author Keywords":"architectural styles classification; deep learning; feature extraction; impact of number kernels\/features; machine intelligence; machine vision","Index Keywords":"Architecture; Classification (of information); Computer vision; Deep learning; Extraction; Learning systems; Architectural style; Architectural style classification; Data set; Deep learning; Features extraction; Impact of number kernel\/feature; Intelligent machine; Machine intelligence; Machine vision model; Machine-vision; Feature extraction","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85153874123"},{"Authors":"Li H.; Dong H.","Author full names":"Li, Huiyu (57842250800); Dong, Hailong (57842250900)","Author(s) ID":"57842250800; 57842250900","Title":"Architectural Style Classification Based on Deep Learning","Year":2025,"Source title":"Computer-Aided Design and Applications","Volume":"22","Issue":null,"Art. No.":null,"Page start":16.0,"Page end":31.0,"Page count":15.0,"Cited by":0,"DOI":"10.14733\/cadaps.2025.S1.16-31","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85197354170&doi=10.14733%2fcadaps.2025.S1.16-31&partnerID=40&md5=13692402d474dec45c267d74131fd16a","Abstract":"This article analyzes the efficient classification of computer models using different architectural styles. A precise feature application for computer-aided design was constructed by evaluating and classifying CAD data training. A deep learning-based model was used for building model training. The research experiment uses the evaluation model's test dataset classification information during the iterative process. Under strict training indicators, the test dataset showed a high-performance level in classifying architectural styles. In the automatic extraction process of architectural images, the method proposed in this article has a high ability for style transformation in processing architectural style data models. In the process of precise automatic extraction of architectural style, the model has a deeper efficiency in building data. This has high accuracy and application value in the style conversion of image architecture. © 2025 U-turn Press LLC.","Author Keywords":"Classification Of Architectural Styles; Computer-Aided Design; Convolutional Neural Network; Data Fusion; Deep Learning","Index Keywords":"Classification (of information); Computer aided design; Computer aided instruction; Convolutional neural networks; Data fusion; Data handling; Extraction; Iterative methods; Metadata; Statistical tests; Architectural style; Automatic extraction; Building model; CAD data; Classification of architectural style; Computer models; Computer-aided design; Convolutional neural network; Deep learning; Learning Based Models; Deep learning","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85197354170"},{"Authors":"Sun K.; Li Q.; Liu Q.; Song J.; Dai M.; Qian X.; Gummidi S.R.B.; Yu B.; Creutzig F.; Liu G.","Author full names":"Sun, Kun (57411580600); Li, Qiaoxuan (57194507746); Liu, Qiance (57208016846); Song, Jinchao (57191960351); Dai, Menglin (57212503765); Qian, Xingjian (57210943201); Gummidi, Srinivasa Raghavendra Bhuvan (57208779486); Yu, Bailang (15840948500); Creutzig, Felix (23995215600); Liu, Gang (57201565364)","Author(s) ID":"57411580600; 57194507746; 57208016846; 57191960351; 57212503765; 57210943201; 57208779486; 15840948500; 23995215600; 57201565364","Title":"Urban fabric decoded: High-precision building material identification via deep learning and remote sensing","Year":2025,"Source title":"Environmental Science and Ecotechnology ","Volume":"24","Issue":null,"Art. No.":"100538","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1016\/j.ese.2025.100538","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85217756418&doi=10.1016%2fj.ese.2025.100538&partnerID=40&md5=88f047b541796956ba0fee7a4b632bb8","Abstract":"Precise identification and categorization of building materials are essential for informing strategies related to embodied carbon reduction, building retrofitting, and circularity in urban environments. However, existing building material databases are typically limited to individual projects or specific geographic areas, offering only approximate assessments. Acquiring large-scale and precise material data is hindered by inadequate records and financial constraints. Here, we introduce a novel automated framework that harnesses recent advances in sensing technology and deep learning to identify roof and facade materials using remote sensing data and Google Street View imagery. The model was initially trained and validated on Odense's comprehensive dataset and then extended to characterize building materials across Danish urban landscapes, including Copenhagen, Aarhus, and Aalborg. Our approach demonstrates the model's scalability and adaptability to different geographic contexts and architectural styles, providing high-resolution insights into material distribution across diverse building types and cities. These findings are pivotal for informing sustainable urban planning, revising building codes to lower carbon emissions, and optimizing retrofitting efforts to meet contemporary standards for energy efficiency and emission reductions. © 2025","Author Keywords":"Building material intensity; Built environment; Deep learning; Remote sensing; Streetview image","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85217756418"},{"Authors":"Sun M.; Zhang F.; Duarte F.; Ratti C.","Author full names":"Sun, Maoran (57223105660); Zhang, Fan (57202400553); Duarte, Fabio (55150497000); Ratti, Carlo (35230766400)","Author(s) ID":"57223105660; 57202400553; 55150497000; 35230766400","Title":"Understanding architecture age and style through deep learning","Year":2022,"Source title":"Cities","Volume":"128","Issue":null,"Art. No.":"103787","Page start":null,"Page end":null,"Page count":null,"Cited by":80,"DOI":"10.1016\/j.cities.2022.103787","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85131439428&doi=10.1016%2fj.cities.2022.103787&partnerID=40&md5=f8ba7449f9837a01ef99b7ac5d150874","Abstract":"Architectural styles and their evolution are central to architecture history. However, traditional approaches to understand styles and their evolution require domain expertise, fieldwork and extensive manual processes. Recent research in deep learning and computer vision has highlighted the great potential in analyzing urban environments from images. In this paper, we propose a deep learning-based framework for understanding architectural styles and age epochs by deciphering building façades based on street-level imagery. The framework is composed of two stages: Deep ‘Learning’ the architecture and Deep ‘Interpreting’ the architecture age epochs and styles. In Deep ‘Learning’, a deep convolutional neural network (DCNN) model is designed to automatically learn about the age characteristics of building façades from street view images. In Deep ‘Interpreting’ stage, three components are proposed to understand the different perspectives regarding building ages and styles. In the experiment, a building age epoch dataset is compiled for the city of Amsterdam and Stockholm to understand the evolution of architectural element styles and the relationship between building ages and styles spatially and temporally. This research illustrates how publicly available data and deep learning could be used to trace the evolution of architectural styles in the spatial-temporal domain. © 2022","Author Keywords":"Architectural style; Building age; Built environment; Deep learning; Street view imagery","Index Keywords":"Amsterdam [North Holland]; Netherlands; North Holland; Stockholm [Stockholm (CNT)]; Stockholm [Sweden]; Sweden; architectural design; building; computer vision; imagery; machine learning; urban area","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85131439428"},{"Authors":"Chen J.; Stouffs R.; Biljecki F.","Author full names":"Chen, Jielin (57196109045); Stouffs, Rudi (6506322664); Biljecki, Filip (55609188900)","Author(s) ID":"57196109045; 6506322664; 55609188900","Title":"Hierarchical (multi-label) architectural image recognition and classification","Year":2021,"Source title":"Projections - Proceedings of the 26th International Conference of the Association for Computer-Aided Architectural Design Research in Asia, CAADRIA 2021","Volume":"1","Issue":null,"Art. No.":null,"Page start":161.0,"Page end":170.0,"Page count":9.0,"Cited by":7,"DOI":null,"Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85104623071&partnerID=40&md5=d850b645e25cdd2956a3bcc2725b8559","Abstract":"The task of architectural image recognition for both architectural functionality and style remains an open challenge. In addition, the paucity of well-organized, large-scale architectural image datasets with specific consideration for the domain of architectural design research has hindered the exploration of these challenging tasks. Drawing upon images from the professional architectural website Archdaily®, and leveraging state-of-the-art deep-learning-based classification models, we explore a hierarchical multi-label classification model as a potential baseline for the task of architectural image classification. The resulting model showcases the potential for innovative architectural discipline-related analyses and demonstrates some heuristic insights for visual feature extraction pertaining to both architectural functionality and architectural style. © 2021 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.","Author Keywords":"Architectural functionality; Hierarchical classification; Image recognition; Multi-label classification; Style","Index Keywords":"Classification (of information); Deep learning; Image classification; Image recognition; Large dataset; Architectural images; Architectural style; Classification models; Hierarchical multi-label classifications; Multi-label; State of the art; Visual feature extraction; Architectural design","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85104623071"},{"Authors":"Tejeswari B.; Sharma S.K.; Kumar M.; Gupta K.","Author full names":"Tejeswari, B. (57742579400); Sharma, S.K. (57198534942); Kumar, M. (55367343600); Gupta, K. (57203610788)","Author(s) ID":"57742579400; 57198534942; 55367343600; 57203610788","Title":"BUILDING FOOTPRINT EXTRACTION FROM SPACE-BORNE IMAGERY USING DEEP NEURAL NETWORKS","Year":2022,"Source title":"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","Volume":"43","Issue":"B2-2022","Art. No.":null,"Page start":641.0,"Page end":647.0,"Page count":6.0,"Cited by":6,"DOI":"10.5194\/isprs-archives-XLIII-B2-2022-641-2022","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85132034919&doi=10.5194%2fisprs-archives-XLIII-B2-2022-641-2022&partnerID=40&md5=52ea027c21d932cef47c7d1a25e4c527","Abstract":"One of the important and high-level detailing contained within basemaps is the ĝ€building feature'. Though pre-trained Deep Learning (DL) models are available for Building Feature Extraction (BFE), they are not efficient in predicting the buildings in other locations. This study explores the need and the major issue of implementing DL models for BFE from Very High Resolution Remote Sensing (VHRS) satellite data for any given area. Though advanced DL models are invented, in order to implement them, huge amount of potential training data is demanded for feed in. the building typologies are highly subjected to the context of study area including soil characteristics, culture\/lifestyle\/economy, architectural style and the building byelaws. The study believes that availability of enough training data of contextual buildings as one of the concern for effective model training. The study aims to extract the buildings present in the study area from Pleiades 1A (2019) RGB VHRS data using simple Mask R-CNN instance segmentation model which is training on the native contextual buildings. Here, an automated method of generating the location-specific training data for a given area is followed using Google Maps API (2021). The generated training data when trained on a deep learning architecture and predicted by the input data yielded promising results. The prediction accuracy of about 98.41% specificity, 96.20% predictive accuracy and 0.89 F1 score are achieved. The methods adopted assist the planning\/governing bodies to accelerate the qualitative urban map preparation.  © 2022. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved. ","Author Keywords":"Building foot-pint extraction; Deep Learning; Mask RCNN; Open Source training data; Open Street Map; Remote Sensing; Satellite imagery","Index Keywords":"Buildings; Deep neural networks; Extraction; Satellite imagery; Space optics; Building foot-pint extraction; Deep learning; Learning models; Mask RCNN; Open source training data; Open street map; Open-source; Remote-sensing; Street maps; Training data; Remote sensing","Document Type":"Conference paper","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85132034919"},{"Authors":"Obeso A.M.; Benois-Pineau J.; Acosta A.Á.R.; Vázquez M.S.G.","Author full names":"Obeso, Abraham Montoya (57016511800); Benois-Pineau, Jenny (6701750610); Acosta, Alejandro Álvaro Ramirez (6602671796); Vázquez, Mireya Saraí García (24366173900)","Author(s) ID":"57016511800; 6701750610; 6602671796; 24366173900","Title":"Architectural style classification of Mexican historical buildings using deep convolutional neural networks and sparse features","Year":2017,"Source title":"Journal of Electronic Imaging","Volume":"26","Issue":"1","Art. No.":"011016","Page start":null,"Page end":null,"Page count":null,"Cited by":39,"DOI":"10.1117\/1.JEI.26.1.011016","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85007240156&doi=10.1117%2f1.JEI.26.1.011016&partnerID=40&md5=0f37f2e4d6b2c567a82e54fc11dd102b","Abstract":"We propose a convolutional neural network to classify images of buildings using sparse features at the network's input in conjunction with primary color pixel values. As a result, a trained neuronal model is obtained to classify Mexican buildings in three classes according to the architectural styles: prehispanic, colonial, and modern with an accuracy of 88.01%. The problem of poor information in a training dataset is faced due to the unequal availability of cultural material. We propose a data augmentation and oversampling method to solve this problem. The results are encouraging and allow for prefiltering of the content in the search tasks. © 2016 SPIE and IS&T.","Author Keywords":"classification; convolutional neural network; cultural heritage; deep learning; image processing; indexing","Index Keywords":"Architecture; Classification (of information); Convolution; Image processing; Indexing (materials working); Indexing (of information); Architectural style; Convolutional neural network; Cultural heritages; Data augmentation; Deep learning; Historical buildings; Poor information; Training dataset; Neural networks","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85007240156"},{"Authors":"Ji Y.; Dong Y.; Hou M.; Qi Y.; Li A.","Author full names":"Ji, Y. (57219031830); Dong, Y. (57194640723); Hou, M. (12773745000); Qi, Y. (57215818562); Li, A. (57204331975)","Author(s) ID":"57219031830; 57194640723; 12773745000; 57215818562; 57204331975","Title":"An extraction method for roof point cloud of ancient building using deep learning framework","Year":2021,"Source title":"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","Volume":"46","Issue":"M-1-2021","Art. No.":null,"Page start":321.0,"Page end":327.0,"Page count":6.0,"Cited by":5,"DOI":"10.5194\/isprs-Archives-XLVI-M-1-2021-321-2021","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85118569784&doi=10.5194%2fisprs-Archives-XLVI-M-1-2021-321-2021&partnerID=40&md5=efc92107e3b55e35830767fd1dc33acb","Abstract":"Chinese ancient architecture is a valuable heritage wealth, especially for roof that reflects the construction age, structural features and cultural connotation. Point cloud data, as a flexible representation with characteristics of fast, precise, non-contact, plays a crucial role in a variety of applications for ancient architectural heritage, such as 3D fine reconstruction, HBIM, disaster monitoring etc. However, there are still many limitations in data editing tasks that need to be worked out manually, which is time-consuming, labor-intensive and error-prone. In recent years, the theoretical advance on deep learning has stimulated the development of various domains, and digital heritage is not in exception. Whenever, deep learning algorithm need to consume a huge amount of labeled date to achieve the purpose for segmentation, resulting a actuality that high labor costs also be acquired. In this paper, inspired by the architectural style similarity between mimetic model and real building, we proposed a method supported by deep learning, which aims to give a solution for the point cloud automatic extraction of roof structure. Firstly, to generate real point cloud, Baoguang Temple, unmanned Aerial Vehicle (UAV) is presented to obtain image collections that are subsequently processed by reconstruction technology. Secondly, a modified Dynamic Graph Convolutional Neural Network (DGCNN) which can learn local features with taking advantage of an edge attention convolution is trained using simulated data and additional attributes of geometric attributes. The mimetic data is sampled from 3DMAX model surface. Finally, we try to extract roof structure of ancient building from real point clouds scenes utilizing the trained model. The experimental results show that the proposed method can extract the rooftop structure from real scene of Baoguang, which illustrates not only effectiveness of approach but also a fact that the simulated source perform potential value when real point cloud datasets are scarce. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All Rights Reserved.","Author Keywords":"Ancient Building; Deep Learning; DGCNN; Point Cloud Segmentation; Roof Extraction","Index Keywords":"Antennas; Buildings; Convolution; Deep learning; Extraction; Image reconstruction; Neural networks; Roofs; Unmanned aerial vehicles (UAV); Wages; Ancient buildings; Deep learning; Dynamic graph; Dynamic graph convolutional neural network; Extraction method; Mimetics; Point cloud segmentation; Point-clouds; Roof extraction; Roof structures; Graph neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85118569784"},{"Authors":"Ruga T.; Caroprese L.; Vocaturo E.; Zumpano E.","Author full names":"Ruga, Tommaso (58883970800); Caroprese, Luciano (22833448800); Vocaturo, Eugenio (57188803544); Zumpano, Ester (6601916208)","Author(s) ID":"58883970800; 22833448800; 57188803544; 6601916208","Title":"Feasibility Analysis of an AI-Based Classification System for Cultural Heritage Building","Year":2024,"Source title":"2024 IEEE International Workshop on Metrology for Living Environment, MetroLivEnv 2024 - Proceedings","Volume":null,"Issue":null,"Art. No.":null,"Page start":87.0,"Page end":91.0,"Page count":4.0,"Cited by":0,"DOI":"10.1109\/MetroLivEnv60384.2024.10615638","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85201201577&doi=10.1109%2fMetroLivEnv60384.2024.10615638&partnerID=40&md5=5f1ed9d542752a42a9f8d22f1a756d25","Abstract":"The country's historical and artistic heritage represents its identity and history. Art cities are often influenced by different architectural styles, sometimes easily distinguishable, thanks to characteristic elements, other times less so, due to influences caused by transition periods from one style to another, or by interventions over the centuries. Artificial Intelligence in recent years, has proven to be a valuable tool in the field of image classification, given its capacity to yield robust solutions across diverse domains. However, its application in the cultural heritage building image classification context remains relatively unexplored. This paper presents a preliminary feasibility study aimed at investigating the potential of deep learning techniques for the classification of cultural heritage building images. The goal could be to build a solution that can recognize, given an image of a historic building, the architectural style, which could improve the experience of a tourist who wants to know more about the visited place's history. The paper examines the results obtained with different neural network architectures, exploiting the Transfer Learning technique, but also draws attention to the challenges of the domain. Overall, encouraging results (AUC 0.98 and F1-score equal to 94-95%), demonstrate the effectiveness of the techniques tested and show how AI can help the classification and preservation of cultural heritage building. © 2024 IEEE.","Author Keywords":"Cultural Heritage Buildings; Images Classification; Transfer Learning","Index Keywords":"Architecture; Deep learning; Historic preservation; Image enhancement; Learning algorithms; Learning systems; Network architecture; Neural networks; Transfer learning; Architectural style; Characteristic elements; Classification system; Cultural heritage building; Cultural heritages; Feasibility analysis; Heritage buildings; Images classification; Learning techniques; Transfer learning; Image classification","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85201201577"},{"Authors":"Zhang Y.; Wang B.; Li J.","Author full names":"Zhang, Yan (55235850200); Wang, Boyuan (57799326200); Li, Jimei (58796698200)","Author(s) ID":"55235850200; 57799326200; 58796698200","Title":"Kangba Region of Sichuan based on swin transformer visual model research on the identification of facades of ethnic buildings","Year":2024,"Source title":"Scientific Reports","Volume":"14","Issue":"1","Art. No.":"28742","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1038\/s41598-024-78774-9","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85209733995&doi=10.1038%2fs41598-024-78774-9&partnerID=40&md5=c50338192ca343eaf056784c18518c1b","Abstract":"The protection and restoration of existing buildings requires accurate acquisition of the characteristics of the building facade. The complex, diverse, and irregular distribution characteristics of the building facade components of ethnic minorities have led to a huge workload of field research, surveying, mapping, and calculation, and it is more difficult to extract its facade characteristics accurately. This study proposes a visual model based on the Swin Transformer and applies it to the graphic recognition of ethnic building elevations. The model combines the advantages of the migration learning method and deep neural network technology and is further enriched by layer normalization to improve the stability and extraction ability of model training. In the field survey of ethnic minority buildings in Kangba, Sichuan, 1100 images of local buildings were collected, including 8 different types of ethnic minority buildings. The experimental results show that compared with other mainstream deep neural network models, the Swin Transformer visual model shows excellent predictive performance to prove the effectiveness of the proposed method. This study also uses the t-sne dimension reduction method to verify the feature extraction ability of the Swin Transformer, which contributes to the protection and restoration of ethnic minority buildings, active exploration of energy conservation, digital archiving, and more. Provide theoretical and practical reference in the fields of architectural style and cultural research. © The Author(s) 2024.","Author Keywords":"Deep learning; Ethnic minority buildings; Image recognition; Swin transformer; Transfer learning","Index Keywords":"article; artificial neural network; controlled study; deep learning; deep neural network; dimensionality reduction; energy conservation; ethnic group; feature extraction; human; learning; nonhuman; transfer of learning; workload","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85209733995"},{"Authors":"Vlăsceanu G.V.; Drăguț A.; Sandu G.; Tarbă N.; Voncilă M.-L.; Boiangiu C.-A.; Goga N.","Author full names":"Vlăsceanu, Giorgiana Violeta (57192818593); Drăguț, Alin (58563020200); Sandu, Gabriel (57415672400); Tarbă, Nicolae (57223104037); Voncilă, Mihai-Lucian (57110434400); Boiangiu, Costin-Anton (6506993286); Goga, Nicolae (8727472200)","Author(s) ID":"57192818593; 58563020200; 57415672400; 57223104037; 57110434400; 6506993286; 8727472200","Title":"ARCHITECT: EXTRACTING BUILDING RELATED INFORMATIONS AND CHANGING ARCHITECTURAL STYLE IN AR","Year":2023,"Source title":"UPB Scientific Bulletin, Series C: Electrical Engineering and Computer Science","Volume":"85","Issue":"3","Art. No.":null,"Page start":65.0,"Page end":76.0,"Page count":11.0,"Cited by":0,"DOI":null,"Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85169842177&partnerID=40&md5=b1c35e061c99d938cf0ea3adc756746d","Abstract":"With recent advancements in mobile computing, augmented reality (AR) applications can now achieve real-time performance. AR provides a novel way to engage with our surroundings. Platforms such as ARKit or ARCore make AR app development easy. ARchitect aims to allow users to experience different architectural styles and cultural heritages by altering the appearance of buildings in their environment. The presented solution utilizes deep learning and computer vision techniques to classify architectural styles, which is a challenging task due to the inter-class relationships between styles. The approach presented in the paper alters the style of a building detected from the phone’s camera and retrieves information such as its current style, age, and distance from the user. To train the deep learning models, a publicly available dataset of photos of buildings with 25 different styles is used. The obtained results for architectural style classification surpass state-of-the-art methods, demonstrating the effectiveness of deep learning techniques. Additionally, the presented approach for architectural style transformation is also promising and will improve as new research is conducted in image generation, monocular depth estimation, and surface reconstruction methods. © 2023, Politechnica University of Bucharest. All rights reserved.","Author Keywords":"AR; architectural style change; architectural style classification; image generation; monocular depth estimation; object saliency detection; surface reconstruction","Index Keywords":"Architecture; Deep learning; Image classification; Image enhancement; Image reconstruction; Learning systems; Object detection; Object recognition; Surface reconstruction; Architectural style; Architectural style change; Architectural style classification; Depth Estimation; Image generations; Monocular depth estimation; Object saliency detection; Saliency detection; Surfaces reconstruction; Augmented reality","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85169842177"},{"Authors":"Han Q.; Yin C.","Author full names":"Han, Qing (57948781500); Yin, Chao (57221927168)","Author(s) ID":"57948781500; 57221927168","Title":"Architectural Style Classification of the Chinese Traditional Settlements using Deep Learning","Year":2023,"Source title":"Proceedings of SPIE - The International Society for Optical Engineering","Volume":"12552","Issue":null,"Art. No.":"125522X","Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1117\/12.2667749","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85159308642&doi=10.1117%2f12.2667749&partnerID=40&md5=702541fd6692b2f7737318b1cb2e2d0d","Abstract":"This paper investigates state-of-the-art deep learning techniques to achieve automatic architectural style classification of the Chinese traditional settlements. First, a new annotated dataset is built with six typical Chinese architectural styles, consisting of over 1000 web-crawled images and an original image collection of Chinese traditional settlements. Second, a state-of-the-art convolutional network named DenseNet is benchmarked on the new dataset to learn the effectiveness of the deep learning networks. Yet, the DenseNet network suffered server overfitting on the small-sized new dataset. Third, to overcome the common overfitting problem, a new deep learning framework named DenseNet-TL-Aug is developed by leveraging transfer learning (TL) and data augmentation (DA) techniques, e.g., AutoAugment. The experimental results demonstrate that the new developed framework achieves much better classification performance in classifying the Chinese traditional style images than the original DenseNet, significantly mitigating the overfitting problem. This study will contribute to automated landscape gene recognition as well as the design and development of traditional tourism. © 2023 SPIE.","Author Keywords":"Architectural Style Classification; Chinese Traditional Settlements; Convolutional Neural Networks; Deep learning","Index Keywords":"Architecture; Convolution; Deep learning; Learning systems; Transfer learning; Web crawler; Annotated datasets; Architectural style; Architectural style classification; Chinese traditional settlement; Convolutional neural network; Deep learning; Learning techniques; Over fitting problem; State of the art; Transfer learning; Convolutional neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85159308642"},{"Authors":"Obeso A.M.; Vázquez M.S.G.; Acosta A.A.R.; Benois-Pineau J.","Author full names":"Obeso, Abraham Montoya (57016511800); Vázquez, Mireya S. García (24366173900); Acosta, Alejandro A. Ramirez (6602671796); Benois-Pineau, Jenny (6701750610)","Author(s) ID":"57016511800; 24366173900; 6602671796; 6701750610","Title":"Connoisseur: Classification of styles of Mexican architectural heritage with deep learning and visual attention prediction","Year":2017,"Source title":"ACM International Conference Proceeding Series","Volume":null,"Issue":null,"Art. No.":"a16","Page start":null,"Page end":null,"Page count":null,"Cited by":28,"DOI":"10.1145\/3095713.3095730","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85030784474&doi=10.1145%2f3095713.3095730&partnerID=40&md5=ebea7bdd8927d082c8e87622c3a8b17b","Abstract":"The automatic description of multimedia content was mainly developed for classification tasks, retrieval systems and massive ordering of data. Preservation of cultural heritage is a field of high importance for application to this method. Our problem is classification of architectural styles of buildings in digital photographs of Mexican cultural heritage. The selection of relevant content in the scene for training classification models allows them to be more precise in the classification task. Here we use a saliency-driven approach to predict visual attention in images and use it to train a Convolutional Neural Network to identify the architectural style of Mexican buildings. Also, we present an analysis of the behavior of the models trained under the traditional cropped image and the prominence maps. In this sense, we show that the performance of the saliency-based CNNs is better than the traditional training reaching a classification rate of 97% in validation dataset. It is considered that style identification with this technique can make a wide contribution in video description tasks, specifically in the automatic documentation of Mexican cultural heritage. © 2017 Association for Computing Machinery.","Author Keywords":"CNN; Cultural heritage; Deep learning; Image classification; Visual attention prediction","Index Keywords":"Deep learning; Architectural heritage; Architectural style; Classification tasks; Cultural heritages; Deep learning; Images classification; Multimedia contents; Retrieval systems; Visual Attention; Visual attention prediction; Convolutional neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85030784474"},{"Authors":"Guo K.; Li N.","Author full names":"Guo, Kun (57201083677); Li, Ning (57204467230)","Author(s) ID":"57201083677; 57204467230","Title":"Research on classification of architectural style image based on convolution neural network","Year":2017,"Source title":"Proceedings of 2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference, ITOEC 2017","Volume":"2017-January","Issue":null,"Art. No.":null,"Page start":1062.0,"Page end":1066.0,"Page count":4.0,"Cited by":6,"DOI":"10.1109\/ITOEC.2017.8122517","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85043368172&doi=10.1109%2fITOEC.2017.8122517&partnerID=40&md5=3b49bdf9d3a657b80c26df1ede010403","Abstract":"Deep learning is a new field in machine learning research. Convolution neural network is the most important factor in image recognition. This paper mainly focuses on the network design and parameter optimization of convolution neural network. This paper is first based on the traditional handwritten digital classification framework LeNet-5 to improve, and implements the test on the ten and twenty-five architectural style data set , and then based on ImageNet-k model design ideas to design a deep convolution neural network structure. The experimental results show that the deeper the network level, the more comprehensive the feature of the image, the better the training effect. In this paper, we study the network design and parameters optimization of convolution neural network, and summarize some practical rules of depth classification on image classification, which is very instructive to solve practical problems. © 2017 IEEE.","Author Keywords":"Convolution neural networks; Deep learning; Image classification; Parameter optimization","Index Keywords":"Architecture; Character recognition; Classification (of information); Convolution; Deep learning; Image enhancement; Image recognition; Learning systems; Statistical tests; Architectural style; Convolution neural network; Depth classification; Digital classification; Machine learning research; Parameter optimization; Parameters optimization; Practical problems; Image classification","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85043368172"},{"Authors":"Lotte R.G.; Haala N.; Karpina M.; de Aragão L.E.O.C.; Shimabukuro Y.E.","Author full names":"Lotte, Rodolfo Georjute (56548930600); Haala, Norbert (6601958644); Karpina, Mateusz (57190379189); de Aragão, Luiz Eduardo Oliveira e Cruz (9279986800); Shimabukuro, Yosio Edemir (7006392180)","Author(s) ID":"56548930600; 6601958644; 57190379189; 9279986800; 7006392180","Title":"3D façade labeling over complex scenarios: A case study using convolutional neural network and structure-from-motion","Year":2018,"Source title":"Remote Sensing","Volume":"10","Issue":"9","Art. No.":"1435","Page start":null,"Page end":null,"Page count":null,"Cited by":20,"DOI":"10.3390\/rs10091435","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85053636024&doi=10.3390%2frs10091435&partnerID=40&md5=386b2bcff33fe6b7855d5a39eb743374","Abstract":"Urban environments are regions in which spectral variability and spatial variability are extremely high, with a huge range of shapes and sizes, and they also demand high resolution images for applications involving their study. Due to the fact that these environments can grow even more over time, applications related to their monitoring tend to turn to autonomous intelligent systems, which together with remote sensing data could help or even predict daily life situations. The task of mapping cities by autonomous operators was usually carried out by aerial optical images due to its scale and resolution; however new scientific questions have arisen, and this has led research into a new era of highly-detailed data extraction. For many years, using artificial neural models to solve complex problems such as automatic image classification was commonplace, owing much of their popularity to their ability to adapt to complex situations without needing human intervention. In spite of that, their popularity declined in the mid-2000s, mostly due to the complex and time-consuming nature of their methods and workflows. However, newer neural network architectures have brought back the interest in their application for autonomous classifiers, especially for image classification purposes. Convolutional Neural Networks (CNN) have been a trend for pixel-wise image segmentation, showing flexibility when detecting and classifying any kind of object, even in situations where humans failed to perceive differences, such as in city scenarios. In this paper, we aim to explore and experiment with state-of-the-art technologies to semantically label 3D urban models over complex scenarios. To achieve these goals, we split the problem into two main processing lines: first, how to correctly label the façade features in the 2D domain, where a supervised CNN is used to segment ground-based façade images into six feature classes, roof, window, wall, door, balcony and shop; second, a Structure-from-Motion (SfM) and Multi-View-Stereo (MVS) workflow is used to extract the geometry of the façade, wherein the segmented images in the previous stage are then used to label the generated mesh by a \"reverse\" ray-tracing technique. This paper demonstrates that the proposed methodology is robust in complex scenarios. The façade feature inferences have reached up to 93% accuracy over most of the datasets used. Although it still presents some deficiencies in unknown architectural styles and needs some improvements to be made regarding 3D-labeling, we present a consistent and simple methodology to handle the problem. © 2018 by the authors.","Author Keywords":"3D reconstruction; Deep-learning; Façade feature detection; Structure-from-motion","Index Keywords":"Antennas; Complex networks; Convolution; Deep learning; Image classification; Image segmentation; Intelligent systems; Network architecture; Neural networks; Problem solving; Ray tracing; Remote sensing; Roofs; 3D reconstruction; Automatic image classification; Autonomous intelligent systems; Convolutional neural network; Convolutional Neural Networks (CNN); Feature detection; State-of-the-art technology; Structure from motion; Stereo image processing","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access; Green Open Access","Source":"Scopus","EID":"2-s2.0-85053636024"},{"Authors":"Xu H.; Wang L.; Fang Z.; He M.; Hou X.; Zuo L.; Guan F.; Xiong C.; Gong Y.; Pang Q.; Zhang H.; Sun S.; Nadire A.","Author full names":"Xu, Hong (57203983522); Wang, Lubin (57224113359); Fang, Zhixiang (9632604800); He, Minghui (57224105947); Hou, Xuecheng (57224113165); Zuo, Liang (57217311880); Guan, Fangli (57218328129); Xiong, Ce (57224110241); Gong, Yiyu (57224101617); Pang, Qinglin (57224104987); Zhang, Han (56012534200); Sun, Shuteng (57224115248); Nadire, Aimaier (57224111220)","Author(s) ID":"57203983522; 57224113359; 9632604800; 57224105947; 57224113165; 57217311880; 57218328129; 57224110241; 57224101617; 57224104987; 56012534200; 57224115248; 57224111220","Title":"Street-Facing Architectural Image Mapping and Architectural Style Map Generation Method Using Street View Images; [街景影像下的临街建筑风格映射及地图生成方法]","Year":2021,"Source title":"Wuhan Daxue Xuebao (Xinxi Kexue Ban)\/Geomatics and Information Science of Wuhan University","Volume":"46","Issue":"5","Art. No.":null,"Page start":659.0,"Page end":671.0,"Page count":12.0,"Cited by":3,"DOI":"10.13203\/j.whugis20200445","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85106970571&doi=10.13203%2fj.whugis20200445&partnerID=40&md5=6440c1dc8dcb8369e27c267d02a0aced","Abstract":"Objectives: Each region has specific characteristics of architectural styles, and a detailed investigation of the geographical distribution of architectural styles is conducive to the protection of historic buildings, the development of special tourism resources and the scientific planning of urban architectural areas. However, the number of urban buildings is large, manual collection and investigation cannot meet the needs of large-scale operations. In recent years, Google and other Internet companies have launched street view images. Street view images are high resolution, containing a full range of urban street views as well as precise location and posture information, which provide a possibility to explore the geographic distribution of urban architectural styles. Therefore, we use deep learning to identify and match the styles of street view building areas, and establish a mapping relationship between the building area images and building outlines, so as to construct the generation method of a large-scale urban architectural style map in detail. Methods: The style identification and map matching of architectural areas in street view images are the key and difficulty in generating urban architectural style maps. Firstly, we extract the building area images of various styles through Faster R-CNN. In order to establish the mapping relationship between building area images and single building outlines, we construct a building location mapping method by matching the same name building area in two adjacent street view images, then the building can be located by forward intersection. Secondly, for the single building image without a same-name area, we also propose a building azimuth mapping method, which combines the spatial azimuth relationship between the street view building area and building outlines in a digital map. The intersection of union (IoU) of the single building image azimuth range and the building outline azimuth range can help match the building area in a street view image and building outlines in a digital map. Finally, Technique for order preference by similarity to an ideal solution is used to determine the unique style attribute of each map building outline to solve the multiple mapping problem of a single building and generate a fine-grained architectural style map. Results: The experimental results of the proposed method are as follows: (1) The average accuracy of Faster R-CNN detection of 19 types of architectural style areas on the test set is 73.81%. (2) The accuracy of matching two adjacent street images with the same name architectural area is 86.1%, the recall is 90.3%, and the average time to match an architectural region pair is 180.1 ms, which is 25.4% less than the time using SURF(speeded up robust features) under spherical epipolar geometry constraint and an accuracy improvement of 19.4%; (3) The accuracy of a building location mapping method is 85.1%, the mapping success rate is only 49.33%, and the average time for two corresponding building area to complete location mapping is 2.741 s; the accuracy of the building azimuth mapping method is 80.3%, the mapping success rate is 88.0%, and the average time for a single building area to complete azimuth mapping is 0.017 s. (4) In the test region, the building azimuth mapping method is more likely to cause multiple mapping problems, with 42.9% of the building outlines matching to multiple building images compared to 23.4% for the building location mapping method. (5) By verifying the style attributes of 331 building outlines in a digital map, we obtain a mean classification accuracy of 55.1%, a mean recall of 76.4%, and a mean F1 score of 0.601 for the architectural style maps. Conclusions: Under the two architectural area mapping methods, the generation time of architectural style maps is short, and the F1 score of classification is 0.601, which can basically reflect the geographic distribution characteristics of a large range of urban architectural styles. In addition, the regional and similarity of architectural styles is the main reason for the difficulty in classifying architectural style images, which affects the classification accuracy of architectural style maps and can be studied in more depth in the future. © 2021, Editorial Board of Geomatics and Information Science of Wuhan University. All right reserved.","Author Keywords":"Architectural style classification; Building visual localization; Deep learning; Street view image matching; Street view images","Index Keywords":"Convolutional neural networks; Deep learning; Geographical distribution; Image enhancement; Location; Tourism; Accuracy Improvement; Architectural images; Classification accuracy; Distribution characteristics; Forward intersections; Mapping relationships; Speeded up robust features; Style identifications; classification; digital map; geographical distribution; historic building; machine learning; mapping; urban area; Architecture","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85106970571"},{"Authors":"Tyagi H.; Kumar V.; Kumar G.","Author full names":"Tyagi, Himanshu (58149204600); Kumar, Vivek (57688256700); Kumar, Gaurav (55259095400)","Author(s) ID":"58149204600; 57688256700; 55259095400","Title":"A Review Paper on Real-Time Video Analysis in Dense Environment for Surveillance System","Year":2022,"Source title":"2022 International Conference on 4th Industrial Revolution Based Technology and Practices, ICFIRTP 2022","Volume":null,"Issue":null,"Art. No.":null,"Page start":171.0,"Page end":183.0,"Page count":12.0,"Cited by":4,"DOI":"10.1109\/ICFIRTP56122.2022.10059434","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85150424458&doi=10.1109%2fICFIRTP56122.2022.10059434&partnerID=40&md5=3a7d3023463b7b4fae4f5a387f2e3a53","Abstract":"Dense environmental conditions such as snow, fog, lightning, heavy rain, and darkness drastically lower the quality of outdoor surveillance videos. The primary functions of video surveillance systems in crowded environments have received significant attention, particularly in detection, categorization, and event or object recognition. The methods and algorithms for real-Time video analysis in various weather conditions have also significantly advanced with the advancement of technology. Examples include background extraction, the see-Through algorithm, deep learning models, CNN for nighttime intrusions, the System for high-quality underwater Monitoring using optical-wireless video surveillance, the low-visibility enhancement network (LVENet), edge computing, and many others. Using various elements of these methodologies, the current research increased monitoring performance and avoided potential human failures. In-depth information about these video surveillance methods, systems, and supporting details is provided in this study. An overview of employed construction and architectural styles is given, and the critical assessments of these systems are then covered. Current surveillance systems and various methods for achieving accuracy in real-Time video analysis in adverse weather circumstances are contrasted in terms of their features, benefits, and challenges, which are discussed in this paper, to provide a complete image and a broad view of the System. Future trends are also highlighted, pointing to the study that will be conducted in the future.  © 2022 IEEE.","Author Keywords":"CNN; deep learning; Dense environment; Edge computing; GAN; LIVnet; Video surveillance; VNS; YOLOv3; YOLOv5","Index Keywords":"Deep learning; Edge computing; Real time systems; Security systems; Deep learning; Dense environment; Edge computing; GAN; Livnet; Real-time video analysis; Video surveillance; VNS; YOLOv3; YOLOv5; Object recognition","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85150424458"},{"Authors":"Zhong T.; Zhang Z.; Chen M.; Zhang K.; Zhou Z.; Zhu R.; Wang Y.; Lü G.; Yan J.","Author full names":"Zhong, Teng (56237541500); Zhang, Zhixin (57221095424); Chen, Min (55733214300); Zhang, Kai (57307349000); Zhou, Zixuan (57221093394); Zhu, Rui (56754542900); Wang, Yijie (57209053179); Lü, Guonian (7403460568); Yan, Jinyue (58614435000)","Author(s) ID":"56237541500; 57221095424; 55733214300; 57307349000; 57221093394; 56754542900; 57209053179; 7403460568; 58614435000","Title":"A city-scale estimation of rooftop solar photovoltaic potential based on deep learning","Year":2021,"Source title":"Applied Energy","Volume":"298","Issue":null,"Art. No.":"117132","Page start":null,"Page end":null,"Page count":null,"Cited by":112,"DOI":"10.1016\/j.apenergy.2021.117132","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85108084262&doi=10.1016%2fj.apenergy.2021.117132&partnerID=40&md5=040aaaf15b2fe33facfd36c68bfc5802","Abstract":"The estimation of rooftop solar photovoltaic (PV) potential is crucial for policymaking around sustainable energy plans. But it is difficult to accurately estimate the availability of rooftop area for solar radiation on a city-scale. In this study, a generic framework for estimating the rooftop solar PV potential on a city-scale using publicly available high-resolution satellite images is proposed. A deep learning-based method is developed to extract the rooftop area with image semantic segmentation automatically. A spatial optimization sampling strategy is developed to solve the labor-intensive problem when training the rooftop extraction model based on prior knowledge of urban and rural spatial layout and land use. In the case study of Nanjing, China, the labor cost on preparing the dataset for training the rooftop extraction model has been reduced by about 80% with the proposed spatial optimization sampling strategy. Meanwhile, the robustness of the rooftop extraction model in districts with different architectural styles and land use has been improved. The total rooftop area extracted was 330.36 km2, and the overall accuracy reached 0.92. The estimation results show that Nanjing has significant potential for rooftop-mounted PV installations, and the potential installed capacity reached 66 GW. The annual rooftop solar PV potential was approximately 311,853 GWh, with a corresponding estimated power generation of 49,897 GWh in 2019. © 2021 Elsevier Ltd","Author Keywords":"City-scale; Deep learning; geographic information systems (GIS); rooftop solar photovoltaic (PV) potential; Sampling strategy","Index Keywords":"Deep learning; Energy policy; Extraction; Geographic information systems; Image segmentation; Semantics; Solar concentrators; Solar power generation; Wages; City scale; Deep learning; Extraction model; Geographic information system; Nanjing; Photovoltaic potentials; Rooftop solar photovoltaic  potential; Sampling strategies; Solar photovoltaics; Spatial optimization; alternative energy; automation; numerical model; photovoltaic system; policy making; satellite imagery; solar power; solar radiation; Land use","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85108084262"},{"Authors":"Dautov E.; Astafeva N.","Author full names":"Dautov, Eldar (57223093387); Astafeva, Natalia (57205458347)","Author(s) ID":"57223093387; 57205458347","Title":"Convolutional Neural Network in the Classification of Architectural Styles of Buildings","Year":2021,"Source title":"Proceedings of the 2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2021","Volume":null,"Issue":null,"Art. No.":"9396452","Page start":274.0,"Page end":277.0,"Page count":3.0,"Cited by":9,"DOI":"10.1109\/ElConRus51938.2021.9396452","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85104706529&doi=10.1109%2fElConRus51938.2021.9396452&partnerID=40&md5=082c1e90ca4a248ab2135c17df5f4cce","Abstract":"The article focuses on the implementation of the project for the classification of architectural styles of buildings. We use modern deep learning methods using convolutional neural networks for realization of this project. Image classification using CNN has many implementations. However, the recognition of architectural styles is not fully researched. This article presents a neural network capable of determining from a photograph of a building its belonging to a certain style of architecture. We train a deep CNN classifier model to classify buildings belonging to 15 different architectural styles. We use a data set that we have collected from open sources of the global Internet to do this. © 2021 IEEE.","Author Keywords":"Architectural styles; CNN; Deep learning; Image classification","Index Keywords":"Architecture; Convolution; Deep learning; Learning systems; Architectural style; Classifier models; Data set; Global Internet; Learning methods; Open sources; Convolutional neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85104706529"},{"Authors":null,"Author full names":null,"Author(s) ID":null,"Title":"Proceedings of the 2024 18th International Conference on Ubiquitous Information Management and Communication, IMCOM 2024","Year":2024,"Source title":"Proceedings of the 2024 18th International Conference on Ubiquitous Information Management and Communication, IMCOM 2024","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":629.0,"Cited by":0,"DOI":null,"Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85188215024&partnerID=40&md5=3504f59ea78f27ca4c851311198f8b24","Abstract":"The proceedings contain 99 papers. The topics discussed include: Deep-RSIv2: an efficient content-free deep learning approach for radiographs’ manufacturer and model identification; unveiling algorithm classification excellence: exploring calendula and coreopsis flower datasets with varied segmentation techniques; memory efficient with parameter efficient fine-tuning for code generation using quantization; emotional subtitles through speech in films: a case study; task execution promotion method by automatic generation of viewer comments for live commentary of work contents; comprehensive assessment of perovskite solar cell efficiency through holistic edge detection analysis of crystallographic grain size; play bricks IV: desktop and web-based play bricks app for architectural styles; and navigating digital transformation challenges: an exploration of employee attitudes, expectations, and support.","Author Keywords":null,"Index Keywords":null,"Document Type":"Conference review","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85188215024"},{"Authors":"Obeso A.M.; Benois-Pineau J.; Vázquez M.S.G.; Acosta A.A.R.","Author full names":"Obeso, A. Montoya (57016511800); Benois-Pineau, J. (6701750610); Vázquez, M. S. García (24366173900); Acosta, A. A. Ramírez (6602671796)","Author(s) ID":"57016511800; 6701750610; 24366173900; 6602671796","Title":"Saliency-based selection of visual content for deep convolutional neural networks: Application to architectural style classification","Year":2019,"Source title":"Multimedia Tools and Applications","Volume":"78","Issue":"8","Art. No.":null,"Page start":9553.0,"Page end":9576.0,"Page count":23.0,"Cited by":13,"DOI":"10.1007\/s11042-018-6515-2","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85053042423&doi=10.1007%2fs11042-018-6515-2&partnerID=40&md5=5328845d43de22566067e32cc0a874ec","Abstract":"The automatic description of digital multimedia content was mainly developed for classification tasks, retrieval systems and massive ordering of data. Preservation of cultural heritage is a field of high importance of application of these methods. We address classification problem in cultural heritage such as classification of architectural styles in digital photographs of Mexican cultural heritage. In general, the selection of relevant content in the scene for training classification models makes the models more efficient in terms of accuracy and training time. Here we use a saliency-driven approach to predict visual attention in images and use it to train a Deep Convolutional Neural Network. Also, we present an analysis of the behavior of the models trained under the state-of-the-art image cropping and the saliency maps. To train invariant models to rotations, data augmentation of training set is required, which posses problems of filling normalization of crops, we study were different padding techniques and we find an optimal solution. The results are compared with the state-of-the-art in terms of accuracy and training time. Furthermore, we are studying saliency cropping in training and generalization for another classical task such as weak labeling of massive collections of images containing objects of interest. Here the experiments are conducted on a large subset of ImageNet database. This work is an extension of preliminary research in terms of image padding methods and generalization on large scale generic database. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Author Keywords":"Cultural heritage; Data selection; Deep learning; Visual attention prediction","Index Keywords":"Architecture; Behavioral research; Convolution; Deep learning; Historic preservation; Image processing; Neural networks; Search engines; Architectural style; Classification models; Classification tasks; Cultural heritages; Data Selection; Deep convolutional neural networks; Digital photographs; Visual Attention; Deep neural networks","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85053042423"},{"Authors":"Loufakis M.; Symeonidis P.; Fontalis S.; Ioannidis D.; Tzovaras D.","Author full names":"Loufakis, M. (58499216000); Symeonidis, P. (57213617645); Fontalis, S. (58655793800); Ioannidis, D. (19638392200); Tzovaras, D. (13105681700)","Author(s) ID":"58499216000; 57213617645; 58655793800; 19638392200; 13105681700","Title":"Employing Deep Learning Framework to Support Location Management for the Audio-Visual Industry","Year":2023,"Source title":"2023 8th International Conference on Image, Vision and Computing, ICIVC 2023","Volume":null,"Issue":null,"Art. No.":null,"Page start":942.0,"Page end":947.0,"Page count":5.0,"Cited by":0,"DOI":"10.1109\/ICIVC58118.2023.10270287","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85175611328&doi=10.1109%2fICIVC58118.2023.10270287&partnerID=40&md5=8e58e5a2cd659bb50c3c6cda0fcf3bcd","Abstract":"This paper presents a specialized tool for film producers and managers to extract useful information from images of different locations. The resulting framework can be used for image retrieval and other applications related to film production and location scouting. The framework uses deep learning models to extract labels, colors, seasons, emotions, and building architecture from input images. The methodology is described in detail, outlining the different steps involved in image processing and feature extraction. The label extraction module uses a transfer learning approach with pre-trained CNN models fine-tuned on a custom dataset of 106 classes. The color extraction module uses the LAB color space, a device-independent and perceptually uniform color space, in image processing applications, to accurately identify the dominant color, while the season extraction module extracts seasonal information from input images. The emotion extraction module identifies the emotion portrayed in an image, and the architectural style module automatically identifies the style of buildings in photos. Finally, the embedding module combines various vectors representing different image aspects to create a general embedding for each image. © 2023 IEEE.","Author Keywords":"artificial intelligence; building architecture identification; CNN models; color extraction; deep learning; embedding; emotion extraction; feature extraction; film production; image processing; image retrieval; LAB color space; label extraction; location scouting; season extraction; transfer learning","Index Keywords":"Color; Deep learning; Embeddings; Extraction; Feature extraction; Image processing; Image retrieval; Location; Building architecture identification; CNN models; Color extraction; Colour spaces; Deep learning; Embeddings; Emotion extractions; Features extraction; Film production; Images processing; LAB color space; Label extraction; Location scouting; Season extraction; Transfer learning; Architecture","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85175611328"},{"Authors":"Nogales A.; Delgado-Martos E.; Melchor Á.; García-Tejedor Á.J.","Author full names":"Nogales, Alberto (56278130700); Delgado-Martos, Emilio (55816806600); Melchor, Ángel (57223317397); García-Tejedor, Álvaro J. (27567618300)","Author(s) ID":"56278130700; 55816806600; 57223317397; 27567618300","Title":"ARQGAN: An evaluation of generative adversarial network approaches for automatic virtual inpainting restoration of Greek temples","Year":2021,"Source title":"Expert Systems with Applications","Volume":"180","Issue":null,"Art. No.":"115092","Page start":null,"Page end":null,"Page count":null,"Cited by":9,"DOI":"10.1016\/j.eswa.2021.115092","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85105581024&doi=10.1016%2fj.eswa.2021.115092&partnerID=40&md5=7595ac466cfb9f3d08ec9ef5f2719a55","Abstract":"Image reconstruction has received much attention and has advanced in recent years with the rise of deep learning. Deep neural models have been able to perform image-to-image translation by transferring pictorial styles, coloring old photographs or filling in missing parts. This last technique is known as image inpainting and enables restoration of damaged or missing parts of an image or photograph to obtain the complete picture. However, it is not always possible to properly define which parts are missing or to identify where they are missing, as in the case of superimposing new information on an already complete image. In this paper, we propose the use of generative adversarial networks (GANs), a well-known deep learning model, for virtual inpainting restoration of artificial landscape images containing archaeological remains of Greek temples. The network identifies key features determined by the internal logic of the architectural style denoted by the ruins and adds the missing architectural elements to obtain an image of the restored building. Unlike other studies, it does not receive any information on which elements should be added or where. Virtual inpainting restoration is capable of representing a building's envelope but also integrates particular aspects of the building related to the architectural language used for its design. The restoration of the fundamental parts of the classical Greek order was consistent, and the results were evaluated with objective metrics and through a subjective survey between academics and architects. They showed that adding segmented images to the training dataset gives better results. © 2021 Elsevier Ltd","Author Keywords":"Deep Learning; Generative Adversarial Networks; Greek temples; Image inpainting; Segmented training; Virtual restoration","Index Keywords":"Architecture; Deep learning; E-learning; Image reconstruction; Photography; Adversarial networks; Deep learning; Generative adversarial network; Greek Temple; Image Inpainting; Images reconstruction; Inpainting; Neural models; Segmented training; Virtual restoration; Restoration","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85105581024"},{"Authors":"Diker F.; Erkan İ.","Author full names":"Diker, Fadime (57222732561); Erkan, İlker (57190946568)","Author(s) ID":"57222732561; 57190946568","Title":"AN APPROACH WITH DEEP CONVOLUTIONAL NEURAL NETWORKS FOR ACCURATE ARCHITECTURAL STYLE CLASSIFICATION","Year":2024,"Source title":"New Design Ideas","Volume":"8","Issue":"3","Art. No.":null,"Page start":615.0,"Page end":640.0,"Page count":25.0,"Cited by":0,"DOI":"10.62476\/ndi83615","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85213398602&doi=10.62476%2fndi83615&partnerID=40&md5=35e8609118e7d3b4d8df31c1891021a6","Abstract":"Unlike other studies, this study aims to examine the effect of data diversity and quantity on the performance of a model rather than solely focusing on classifying architectural styles. It also seeks to emphasize the importance of selecting the appropriate number of classes in architectural style classification and to explore how determining the optimal number of classes affects the model's success. The first dataset comprises the original images (4776 images), the second dataset (10091 images) includes additional data and the third dataset (9552 images) is obtained through data augmentation. Using these three datasets, models were developed by reducing the number of classes with convolutional neural networks (CNNs), which utilize convolution layers to identify local features in the images and classify them by summarizing these features. The results of the developed models show that the method of adding data and increasing data decreased the success of architectural style classification, whereas reducing the number of styles increased it. This study may lay the groundwork for the development of deep learning models for future architectural style classification. The findings of this study can significantly impact various application areas, such as analyzing architectural styles, identifying historical periods and integrating them into architectural education. © 2024, Jomard Publishing. All rights reserved.","Author Keywords":"Architectural styles; cultural heritage; deep learning; digital documentation; image classification","Index Keywords":null,"Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Bronze Open Access","Source":"Scopus","EID":"2-s2.0-85213398602"},{"Authors":"Schuegraf P.; Zorzi S.; Fraundorfer F.; Bittner K.","Author full names":"Schuegraf, Philipp (57202022995); Zorzi, Stefano (57214136113); Fraundorfer, Friedrich (8977349800); Bittner, Ksenia (57194603356)","Author(s) ID":"57202022995; 57214136113; 8977349800; 57194603356","Title":"Deep Learning for the Automatic Division of Building Constructions into Sections on Remote Sensing Images","Year":2023,"Source title":"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","Volume":"16","Issue":null,"Art. No.":null,"Page start":7186.0,"Page end":7200.0,"Page count":14.0,"Cited by":8,"DOI":"10.1109\/JSTARS.2023.3296449","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85165302287&doi=10.1109%2fJSTARS.2023.3296449&partnerID=40&md5=2c54b35d8536b95bfeac68ed1969b0e9","Abstract":"Urban areas predominantly consist of complex building structures, which are assembled of multiple building sections. From very high resolution remote sensing imagery, not only roof-tops but also the separation lines between them are visible. Since fully convolutional neural network (FCN)-based methods have become the primary choice in segmentation approaches, they have been extensively used for automatic building footprint extraction. But each of the previous works on building segmentation either lacks separation of building blocks into sections or does not produce sections of regular appearance. We propose a two-stage approach to overcome these limitations. The first step segments building and separation lines using an FCN model and the second step produces building instances by using a learning-free method. Our model receives a top-down image and a digital surface model (DSM) patch in two separate encoders. The encoder features are summed before the skip connections, which utilize the encoder features from the current and higher-resolution feature maps. We train our model with regularization losses for building shapes and separation lines on both satellite and aerial imagery. We test our model on a city that was not previously included in the training phase to show that it has the capacity to generalize across different geographical locations and architectural styles. Furthermore, we use our building section instance predictions to generate: 1) vectorized building maps and 2) a level-of-detail-1 DSM.  © 2008-2012 IEEE.","Author Keywords":"Convolutional neural networks; deep learning; semantic segmentation; supervised learning; urban areas","Index Keywords":"Aerial photography; Antennas; Buildings; Deep learning; Extraction; Image segmentation; Neural networks; Satellite imagery; Signal encoding; Building construction; Convolutional neural network; Digital surface models; Features extraction; Images segmentations; Remote sensing images; Remote-sensing; Shape; Spatial resolution; Urban areas; artificial neural network; building construction; image analysis; remote sensing; segmentation; supervised learning; urban area; Remote sensing","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access; Green Open Access","Source":"Scopus","EID":"2-s2.0-85165302287"},{"Authors":"Hieu P.Q.; Thuy N.T.B.","Author full names":"Hieu, Pham Quang (59430433300); Thuy, Nguyen Thi Bich (58254332600)","Author(s) ID":"59430433300; 58254332600","Title":"Data-Driven Interior Plan Generation for Residential Buildings in Vietnam","Year":2024,"Source title":"Lecture Notes in Networks and Systems","Volume":"893","Issue":null,"Art. No.":null,"Page start":57.0,"Page end":70.0,"Page count":13.0,"Cited by":0,"DOI":"10.1007\/978-981-99-9518-9_5","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85189753930&doi=10.1007%2f978-981-99-9518-9_5&partnerID=40&md5=dcd585b0caa23b5e985681aae5498263","Abstract":"We propose a new data-driven technique to automatically and efficiently generate floor plans for residential buildings in Vietnam with certain boundaries. We focus on improving the accuracy of the algorithm that was developed in another country to match the architectural style in Vietnam. Along with collecting a large number of architectural plans in Vietnam, we have proposed a method of semi-automatic data labeling using CNN deep learning network. As the result, we achieved the overall accuracy over 85% for prediction room type and room location on the test dataset. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Author Keywords":"Data-driven approach; Deep learning; Floor plan generation; Neural network","Index Keywords":"Floors; Housing; Statistical tests; Data driven; Data driven technique; Data-driven approach; Deep learning; Floor plan generation; Floorplans; Neural-networks; Plan generation; Residential building; Viet Nam; Deep learning","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85189753930"},{"Authors":"Zhao P.; Miao Q.; Liu R.; Song J.","Author full names":"Zhao, Peipei (57199170604); Miao, Qiguang (9133503300); Liu, Ruyi (56460571700); Song, Jianfeng (55500915300)","Author(s) ID":"57199170604; 9133503300; 56460571700; 55500915300","Title":"Architectural style classification based on DNN model","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11857 LNCS","Issue":null,"Art. No.":null,"Page start":505.0,"Page end":516.0,"Page count":11.0,"Cited by":3,"DOI":"10.1007\/978-3-030-31654-9_43","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85086144925&doi=10.1007%2f978-3-030-31654-9_43&partnerID=40&md5=b93c5a74b3dd70269d485061785ce7e2","Abstract":"Deep neural networks (DNN) have been widely used for image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in architectural style classification. Data augmentation can alleviate this labeling effort. In this paper, we use data augmentation to increase the number of architectural style datasets. To extract building elements, the inputs are preprocessed by Deformable Part Model (DPM) first, and then the preprocessed images are sent to the data augmentation to increase the number of images. Next, we design a deep neural network based on GoogLeNet. The proposed network aims to learn robust feature embeddings to improve architectural style classification performance. Finally, architectural style can be classified by the robust feature embeddings. Experimental results show that our approach achieves promising performance and is superior to previous methods. © Springer Nature Switzerland AG 2019.","Author Keywords":"Architectural style classification; Data augmentation; Deep neural networks; Deformable Part Model; GoogLeNet","Index Keywords":"Architecture; Classification (of information); Computer vision; Deep learning; Embeddings; Architectural style; Building element; Classification performance; Data augmentation; Deformable part models; Learning approach; Deep neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85086144925"},{"Authors":"Wang R.; Gu D.; Wen Z.; Yang K.; Liu S.; Jiang F.","Author full names":"Wang, Rui (58912617700); Gu, Donghao (57203245286); Wen, Zhaojing (57210578094); Yang, Kai (57703361600); Liu, Shaohui (7409458485); Jiang, Feng (56681657800)","Author(s) ID":"58912617700; 57203245286; 57210578094; 57703361600; 7409458485; 56681657800","Title":"Intra-class Classification of Architectural Styles Using Visualization of CNN","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11632 LNCS","Issue":null,"Art. No.":null,"Page start":205.0,"Page end":216.0,"Page count":11.0,"Cited by":4,"DOI":"10.1007\/978-3-030-24274-9_18","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85073910804&doi=10.1007%2f978-3-030-24274-9_18&partnerID=40&md5=fb99d2d8000787dd08a079f4407cad18","Abstract":"The classification of architectural style is one of the most challenging problems in architectural history due to its temporal inter-class relationships between different styles and geographical variation within one style. Previous computer version approaches have primarily focused on general classification of multiple architectural styles based on historical age, but very few studies have attempted deep learning to address intra-class classification problems according to geographical location, which might reveal the significance of local evolution and adaption of ancient architectural style. Therefore, we exemplified gothic architecture as a certain genre and leased a new dataset containing gothic architecture in three different countries: France, England, and Italy. Besides, a trained model is susceptible to overfitting due to fecundity of regional parameters and shortcoming of dataset. In this paper, we propose a new approach to accurately classify intra-class variance in the sense of their geographical locations: visualization of Convolutional Neural Network. Experimentation on this dataset shows that the approach of intra-class classification based on local features achieves high classification rate. We also present interpretable explanations for the results, to illustrate architectural indication of intra-class classification. © 2019, Springer Nature Switzerland AG.","Author Keywords":"Architectural Style Classification; Convolutional Neural Network; Visualization","Index Keywords":"Architecture; Convolution; Deep learning; Flow visualization; Network architecture; Neural networks; Visualization; Architectural style; Classification rates; Computer versions; Convolutional neural network; Geographical locations; Geographical variations; Gothic architectures; New approaches; Classification (of information)","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85073910804"},{"Authors":"Yılmaz E.B.; Akgül Y.S.; Tan F.","Author full names":"Yılmaz, Emirkan Burak (59254768200); Akgül, Yusuf Sinan (6603443254); Tan, Funda (57831699800)","Author(s) ID":"59254768200; 6603443254; 57831699800","Title":"Architectural Works of the Early Republic Period from an Artificial Intelligence Perspective; [Yapay Zekâ Perspektifinden Erken Cumhuriyet Dönemi Mimari Eserleri]","Year":2024,"Source title":"32nd IEEE Conference on Signal Processing and Communications Applications, SIU 2024 - Proceedings","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":0,"DOI":"10.1109\/SIU61531.2024.10600693","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85200903651&doi=10.1109%2fSIU61531.2024.10600693&partnerID=40&md5=b8f4fe1fae1297403c837f26e6e2c893","Abstract":"This study presents a versatile approach integrating various neural network architectures with a focus on classifying architectural works. To address the lack of suitable datasets in the literature, a custom dataset has been created and made publicly available. The study aims to determine the most effective model, taking into account fine details in architectural styles. In this context, a comparative analysis has been conducted on four different convolutional neural network (CNN) architectures, including a baseline model trained from scratch and models using transfer learning methods with VGG, ResNet, and EfficientNet architectures. Through experiments, the EfficientNet architecture was fine-tuned, achieving an accuracy of %84.65 for 3 architects and %74.08 for 16 architects. Additionally, the two obtained models were used as feature extractors to visualize relationships among architects in a 2D space using t-SNE dimension reduction technique. These promising results indicate that these techniques can significantly contribute to architectural style analysis and serve as valuable tools for creating innovative designs through the use of generative artificial intelligence. © 2024 IEEE.","Author Keywords":"architectural style; convolutional neural network; deep learning; image classification","Index Keywords":"Architecture; Convolution; Convolutional neural networks; Deep learning; Learning systems; Network architecture; Transfer learning; Architectural style; Architectural work; Baseline models; Comparative analyzes; Convolutional neural network; Deep learning; Feature extractor; Images classification; Neural network architecture; Transfer learning methods; Image classification","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85200903651"},{"Authors":"Lamas A.; Tabik S.; Cruz P.; Montes R.; Martínez-Sevilla Á.; Cruz T.; Herrera F.","Author full names":"Lamas, Alberto (57206904461); Tabik, Siham (55884151200); Cruz, Policarpo (37028231900); Montes, Rosana (7006522713); Martínez-Sevilla, Álvaro (6602619556); Cruz, Teresa (57219326116); Herrera, Francisco (7102347190)","Author(s) ID":"57206904461; 55884151200; 37028231900; 7006522713; 6602619556; 57219326116; 7102347190","Title":"MonuMAI: Dataset, deep learning pipeline and citizen science based app for monumental heritage taxonomy and classification","Year":2021,"Source title":"Neurocomputing","Volume":"420","Issue":null,"Art. No.":null,"Page start":266.0,"Page end":280.0,"Page count":14.0,"Cited by":33,"DOI":"10.1016\/j.neucom.2020.09.041","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85092227308&doi=10.1016%2fj.neucom.2020.09.041&partnerID=40&md5=f517e272a3a3bc3d3ab3a5ae6e6bcd9b","Abstract":"An important part of art history can be discovered through the visual information in monument facades. However, the analysis of this visual information, i.e, morphology and architectural elements, requires high expert knowledge. An automatic system for identifying the architectural style or detecting the architectural elements of a monument based on one image will certainly help improving our knowledge in art and history. Building such tool is challenging as some styles share architectural elements, the bad conservation state of some monuments and the noise included in the image itself. The aim of this paper is to introduce MonuMAI (Monument with Mathematics and Artificial Intelligence) framework. In particular, (i) we designed MonuMAI dataset rich with expert knowledge considering the proposed architectural styles taxonomy and key elements relationship, which allows addressing several tasks, e.g., monument style classification and architectural elements detection, (ii) we developed MonuMAI deep learning pipeline based on lightweight MonuNet architecture for monument style classification and MonuMAI Key Elements Detection (MonuMAI-KED) model, and (iii) we built citizen science based MonuMAI mobile app that uses the proposed MonuMAI deep learning pipeline trained on MonuMAI dataset for performing in real life conditions. Our experiments show that both MonuNet architecture and the detection model achieve very good results under real life conditions. © 2020","Author Keywords":"Architectural information extraction; Architectural style classification; Convolutional Neural Networks; MonuMAI; Monumental heritage","Index Keywords":"Architecture; E-learning; Historic preservation; Image enhancement; Pipelines; Taxonomies; Architectural element; Architectural style; Automatic systems; Citizen science; Detection models; Expert knowledge; Key elements; Visual information; article; artificial intelligence; citizen science; convolutional neural network; deep learning; extraction; inheritance; mathematics; mobile application; noise; pipeline; taxonomy; Deep learning","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Green Open Access","Source":"Scopus","EID":"2-s2.0-85092227308"},{"Authors":"Kavitha S.; Mohanavalli S.; Bharathi B.; Rahul C.H.; Shailesh S.; Preethi K.","Author full names":"Kavitha, Srinivasan (35778316000); Mohanavalli, S. (37075351500); Bharathi, B. (58494595400); Rahul, C.H. (58497895600); Shailesh, S. (57841716400); Preethi, K. (57219120911)","Author(s) ID":"35778316000; 37075351500; 58494595400; 58497895600; 57841716400; 57219120911","Title":"Classification of Indian Monument Architecture Styles Using Bi-Level Hybrid Learning Techniques","Year":2022,"Source title":"Lecture Notes in Networks and Systems","Volume":"436","Issue":null,"Art. No.":null,"Page start":471.0,"Page end":488.0,"Page count":17.0,"Cited by":1,"DOI":"10.1007\/978-981-19-1012-8_32","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85135816689&doi=10.1007%2f978-981-19-1012-8_32&partnerID=40&md5=82df8e20df9eca1e35a6d28f5c36e932","Abstract":"India is known for its rich architectural and cultural inheritance. In this research work, classification of the Indian historical monuments has been attempted in two levels, primarily based on the time period of its construction and secondly based on its architectural style, using machine learning (ML) and deep learning (DL) techniques. A rich corpus of monument images of varying historical periods and architectural styles has been collected from the web, blogs, and tourism websites. Feature extraction methods such as speeded-up robust feature (SURF), scale-invariant feature transform (SIFT), features from accelerated segment test (FAST), oriented FAST and rotated brief (ORB), Hu moments, image moments, and Zernike moments are used to extract the features from the input images. ML techniques such as decision tree algorithm (ID3) were used for time period classification in the first level and support vector machine (SVM) for classification of architectural style in the second level. Convolutional neural network (CNN) is designed and validated for training and testing images for both the levels of classification to observe the performance of DL technique in monument classification. Results of this research show that features extracted using Hu moments and Zernike moments resulted in improved accuracy compared to other feature sets. CNN outperforms ML approaches in overall accuracy in both levels of monument classification and also for few specific architectural styles. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Author Keywords":"Architectural styles; Convolutional neural network technique; Decision tree algorithm; Indian monuments; Support vector machine algorithm","Index Keywords":null,"Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85135816689"},{"Authors":"Folino F.; Foresta M.F.; Maurmo D.; Ruga T.; Zumpano E.; Vocaturo E.","Author full names":"Folino, Fiorella (59259523400); Foresta, Maria Francesca (59561798000); Maurmo, Danilo (59142931400); Ruga, Tommaso (58883970800); Zumpano, Ester (6601916208); Vocaturo, Eugenio (57188803544)","Author(s) ID":"59259523400; 59561798000; 59142931400; 58883970800; 6601916208; 57188803544","Title":"AI Image-based Systems for Enhancing the Cultural Tourism Experience","Year":2024,"Source title":"Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024","Volume":null,"Issue":null,"Art. No.":null,"Page start":4720.0,"Page end":4726.0,"Page count":6.0,"Cited by":0,"DOI":"10.1109\/BigData62323.2024.10825071","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85217998269&doi=10.1109%2fBigData62323.2024.10825071&partnerID=40&md5=bc7eb797b01201a1b640e5781c0a064f","Abstract":"Technological innovation, conservation and enhancement are key elements for promoting cultural heritage and attracting visitors worldwide. Cultural tourism represents a significant economic and social strategy, capable of stimulating regional development and revitalizing marginalized areas. In recent years, artificial intelligence (AI) has transformed the sector, offering new ways to engage with and preserve cultural assets. This study explores the application of advanced AI techniques, particularly Convolutional Neural Networks (CNNs), to improve the classification and recognition of images related to architectural heritage. A deep learning algorithm specifically designed for cultural heritage enhancement is presented, focusing on the automatic classification of images of buildings and monuments. The analysis includes a comparison between pre-trained models and custom models, highlighting the performance of different approaches. The experimental results demonstrate that our ensemble model achieved 90% accuracy in classifying architectural heritage elements across 10 categories, with the Majority Vote Ensemble approach outperforming individual models by 6-10%. This improved classification accuracy enables more reliable automated systems for cultural heritage documentation and interactive tourist experiences. The research addresses key challenges in architectural heritage classification including variations in preservation state, lighting conditions, and complex backgrounds with multiple elements. The study also investigates the impact of data augmentation and class balancing techniques on model performance, demonstrating how these methods can mitigate limitations in training data availability. The developed ensemble combines state-of-the-art CNN architectures like ResNet50 and EfficientNet with custom models, leveraging their complementary strengths to achieve robust classification across diverse architectural styles and conditions. The adopted approach is supervised, using a training dataset where images are pre-labeled according to specific categories. This allows the algorithm to learn and subsequently predict the categories of new images based on the acquired information. A practical application is proposed to improve visitor experiences and heritage management, paving the way for future technological advancements in the field. © 2024 IEEE.","Author Keywords":"Artificial Intelligence; Augmented Reality; Image Classification; Smart Tourism","Index Keywords":"Tourism; Architectural heritage; Convolutional neural network; Cultural heritages; Custom models; Image based system; Images classification; Key elements; Smart tourism; Technological enhancement; Technological innovation; Convolutional neural networks","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85217998269"},{"Authors":"Xiu H.; Shinohara T.; Matsuoka M.; Inoguchi M.; Kawabe K.; Horie K.","Author full names":"Xiu, Haoyi (57215270239); Shinohara, Takayuki (57215280854); Matsuoka, Masashi (7401543073); Inoguchi, Munenari (36459756400); Kawabe, Ken (57208388444); Horie, Kei (7201734016)","Author(s) ID":"57215270239; 57215280854; 7401543073; 36459756400; 57208388444; 7201734016","Title":"Collapsed building detection using 3D point clouds and deep learning","Year":2020,"Source title":"Remote Sensing","Volume":"12","Issue":"24 1","Art. No.":"4057","Page start":24.0,"Page end":null,"Page count":null,"Cited by":12,"DOI":"10.3390\/rs12244057","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85098259986&doi=10.3390%2frs12244057&partnerID=40&md5=d1b389da5108c5f72681d5ecdc5e562c","Abstract":"Collapsed buildings should be detected with the highest priority during earthquake emergency response, due to the associated fatality rates. Although deep learning-based damage detection using vertical aerial images can achieve high performance, as depth information cannot be obtained, it is difficult to detect collapsed buildings when their roofs are not heavily damaged. Airborne LiDAR can efficiently obtain the 3D geometries of buildings (in the form of point clouds) and thus has greater potential to detect various collapsed buildings. However, there have been few previous studies on deep learning-based damage detection using point cloud data, due to a lack of large-scale datasets. Therefore, in this paper, we aim to develop a dataset tailored to point cloud-based building damage detection, in order to investigate the potential of point cloud data in collapsed building detection. Two types of building data are created: building roof and building patch, which contains the building and its surroundings. Comprehensive experiments are conducted under various data availability scenarios (pre–post-building patch, post-building roof, and post-building patch) with varying reference data. The pre–post scenario tries to detect damage using pre-event and post-event data, whereas post-building patch and roof only use post-event data. Damage detection is implemented using both basic and modern 3D point cloud-based deep learning algorithms. To adapt a single-input network, which can only accept one building’s data for a prediction, to the pre–post (double-input) scenario, a general extension framework is proposed. Moreover, a simple visual explanation method is proposed, in order to conduct sensitivity analyses for validating the reliability of model decisions under the post-only scenario. Finally, the generalization ability of the proposed approach is tested using buildings with different architectural styles acquired by a distinct sensor. The results show that point cloud-based methods can achieve high accuracy and are robust under training data reduction. The sensitivity analysis reveals that the trained models are able to locate roof deformations precisely, but have difficulty recognizing global damage, such as that relating to the roof inclination. Additionally, it is revealed that the model decisions are overly dependent on debris-like objects when surroundings information is available, which leads to misclassifications. By training on the developed dataset, the model can achieve moderate accuracy on another dataset with different architectural styles without additional training. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"3D point clouds; Collapsed buildings; Damage detection; Deep learning; Visual explanation","Index Keywords":"Antennas; Architecture; Damage detection; Large dataset; Learning algorithms; Roofs; Sensitivity analysis; Architectural style; Collapsed buildings; Depth information; Earthquake emergency response; Generalization ability; Large-scale datasets; Misclassifications; Modeling decisions; Deep learning","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85098259986"},{"Authors":"Han Q.; Yin C.; Deng Y.; Liu P.","Author full names":"Han, Qing (57948781500); Yin, Chao (57221927168); Deng, Yunyuan (55220502000); Liu, Peilin (55221147900)","Author(s) ID":"57948781500; 57221927168; 55220502000; 55221147900","Title":"Towards Classification of Architectural Styles of Chinese Traditional Settlements Using Deep Learning: A Dataset, a New Framework, and Its Interpretability","Year":2022,"Source title":"Remote Sensing","Volume":"14","Issue":"20","Art. No.":"5250","Page start":null,"Page end":null,"Page count":null,"Cited by":19,"DOI":"10.3390\/rs14205250","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85140981367&doi=10.3390%2frs14205250&partnerID=40&md5=63d0a206b30d53a02926ca2993a2a354","Abstract":"The classification of architectural style for Chinese traditional settlements (CTSs) has become a crucial task for developing and preserving settlements. Traditionally, the classification of CTSs primarily relies on manual work, which is inefficient and time consuming. Inspired by the tremendous success of deep learning (DL), some recent studies attempted to apply DL networks such as convolution neural networks (CNNs) to achieve automated classification of the architecture styles. However, these studies suffer overfitting problems of the CNNs, leading to inferior classification performance. Moreover, most of the studies apply the CNNs as a black box providing limited interpretability. To address these limitations, a new DL classification framework is proposed in this study to overcome the overfitting problem by transfer learning and learning-based data augmentation technique (i.e., AutoAugment). Furthermore, we also employ class activation map (CAM) visualization technique to help understand how the CNN classifiers work to abstract patterns from the input. Specifically, due to a lack of architectural style datasets for the CTSs, a new annotated dataset is first established with six representative classes. Second, several representative CNNs are leveraged to benchmark the new dataset. Third, to address the overfitting problem of the CNNs, a new DL framework is proposed which combines transfer learning and AutoAugment to improve the classification performance. Extensive experiments are conducted on the new dataset to demonstrate the effectiveness of our framework. The proposed framework achieves much better performance than baselines, greatly mitigating the overfitting problem. Additionally, the CAM visualization technique is harnessed to explain what and how the CNN classifiers implicitly learn for recognizing a specified architectural style. © 2022 by the authors.","Author Keywords":"architectural style classification; AutoAugment; Chinese traditional settlements; CNN interpretability; convolutional neural networks; cultural heritage; deep learning; Grad-CAM; heritage preservation","Index Keywords":"Architecture; Convolution; Convolutional neural networks; Network architecture; Visualization; Activation maps; Architectural style; Architectural style classification; Autoaugment; Chinese traditional settlement; Convolution neural network; Convolution neural network interpretability; Convolutional neural network; Cultural heritages; Deep learning; Grad-class activation map; Heritage preservation; Interpretability; Classification (of information)","Document Type":"Article","Publication Stage":"Final","Open Access":"All Open Access; Gold Open Access","Source":"Scopus","EID":"2-s2.0-85140981367"},{"Authors":"Zemmari A.; Benois-Pineau J.","Author full names":"Zemmari, Akka (6507308959); Benois-Pineau, Jenny (6701750610)","Author(s) ID":"6507308959; 6701750610","Title":"Case study for digital cultural content mining","Year":2020,"Source title":"SpringerBriefs in Computer Science","Volume":null,"Issue":null,"Art. No.":null,"Page start":71.0,"Page end":85.0,"Page count":14.0,"Cited by":0,"DOI":"10.1007\/978-3-030-34376-7_8","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85078856360&doi=10.1007%2f978-3-030-34376-7_8&partnerID=40&md5=791e04c49c477f75fcc1e68584464166","Abstract":"In this chapter we consider an application case of Deep Learning in the task of architectural recognition. The main objective is to identify both: architectural styles and specific architectural structures. We are interested in attention mechanisms in Deep CNNs and explain how real visual attention maps built upon human gaze fixations can help in the training of deep neural networks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.","Author Keywords":null,"Index Keywords":"Architecture; Behavioral research; Data mining; Deep neural networks; Architectural structure; Architectural style; Attention mechanisms; Cultural content; Visual Attention; Deep learning","Document Type":"Book chapter","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85078856360"},{"Authors":"Qian Z.; Chen M.; Sun Z.; Zhang F.; Xu Q.; Guo J.; Xie Z.; Zhang Z.","Author full names":"Qian, Zhen (57221100745); Chen, Min (55733214300); Sun, Zhuo (57740419600); Zhang, Fan (57202400553); Xu, Qingsong (57214084444); Guo, Jinzhao (58680438700); Xie, Zhiwei (57205741175); Zhang, Zhixin (57221095424)","Author(s) ID":"57221100745; 55733214300; 57740419600; 57202400553; 57214084444; 58680438700; 57205741175; 57221095424","Title":"Simultaneous extraction of spatial and attributional building information across large-scale urban landscapes from high-resolution satellite imagery","Year":2024,"Source title":"Sustainable Cities and Society","Volume":"106","Issue":null,"Art. No.":"105393","Page start":null,"Page end":null,"Page count":null,"Cited by":6,"DOI":"10.1016\/j.scs.2024.105393","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85189861815&doi=10.1016%2fj.scs.2024.105393&partnerID=40&md5=851a9112aa4f80d121f484ca233c773c","Abstract":"Understanding urban dynamics requires comprehensive building analysis, yet current methods focusing on specific aspects hinder the production of unified and large-scale inventories. This study introduces a multi-task deep learning network with a flexible architecture for simultaneously extracting spatial and attributional building information from high-resolution satellite images. This method efficiently segments rooftops and classifies buildings by urban function and architectural style of rooftops. Moreover, a strategic spatial sampling scheme from a data-centric perspective, informed by geographic and environmental diversity, optimizes the selection of representative samples to improve training efficiency and predictive accuracy. Comparative analyses demonstrate the framework's superior performance, achieving an F1 score of 84.30% and an intersection over union of 72.86% in rooftop segmentation, and Kappa scores of 74.67% and 70.04% in classifying urban functions and architectural types, outperforming other advanced models by 2% to 25% across various metrics. Additionally, the adaptability of the network ensures that the framework meets diverse accuracy and efficiency requirements. By applying the proposed methodology to Shanghai, a unified city-scale dataset is generated. This dataset underscores the practical applicability and potential influence of the proposed methods in the fields of urban studies and sustainable development. © 2024 Elsevier Ltd","Author Keywords":"Building information extraction; Data-centric approach; Deep learning; High-resolution satellite imagery; Multi-task learning; Spatial sampling","Index Keywords":"Data mining; Deep learning; Efficiency; Learning systems; Satellite imagery; Sustainable development; Building information extraction; Data-centric approaches; Deep learning; High resolution satellite imagery; Large-scales; Multitask learning; Simultaneous extractions; Spatial sampling; Urban dynamics; Urban landscape; architectural design; building; data set; machine learning; satellite imagery; spatiotemporal analysis; sustainable development; urban development; Buildings","Document Type":"Article","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85189861815"},{"Authors":"Yönder V.M.; İpek E.; Çetin T.; Çavka H.B.; Apaydın M.S.; Doğan F.","Author full names":"Yönder, Veli Mustafa (58612439800); İpek, Emre (58864918500); Çetin, Tarık (58864760100); Çavka, Hasan Burak (56743322000); Apaydın, Mehmet Serkan (6507164359); Doğan, Fehmi (35387836500)","Author(s) ID":"58612439800; 58864918500; 58864760100; 56743322000; 6507164359; 35387836500","Title":"Classification of Turkish and Balkan House Architectures Using Transfer Learning and Deep Learning","Year":2024,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"14366","Issue":null,"Art. No.":null,"Page start":398.0,"Page end":408.0,"Page count":10.0,"Cited by":1,"DOI":"10.1007\/978-3-031-51026-7_34","Link":"https:\/\/www.scopus.com\/inward\/record.uri?eid=2-s2.0-85184088628&doi=10.1007%2f978-3-031-51026-7_34&partnerID=40&md5=7a40f3f5e34d9f8fbe71b6312003fb80","Abstract":"Classifying architectural structures is an important and challenging task that requires expertise. Convolutional Neural Networks (CNN), which are a type of deep learning (DL) approach, have shown successful results in computer vision applications when combined with transfer learning. In this study, we utilized CNN based models to classify regional houses from Anatolia and Balkans based on their architectural styles with various pretrained models using transfer learning. We prepared a dataset using various sources and employed data augmentation and mixup techniques to solve the limited data availability problem for certain regional houses to improve the classification performance. Our study resulted in a classifier that successfully distinguishes 15 architectural classes from Anatolia and Balkans. We explain our predictions using grad-cam methodology. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Author Keywords":"architectural classification; cnn; convnext; grad-cam; inception; resnet; transfer learning","Index Keywords":"Architecture; Cams; Convolutional neural networks; Deep learning; Houses; Learning systems; Network architecture; Transfer learning; Anatolia; Architectural classification; Balkans; Cnn; Convnext; Convolutional neural network; Grad-cam; Inception; Resnet; Transfer learning; Classification (of information)","Document Type":"Conference paper","Publication Stage":"Final","Open Access":null,"Source":"Scopus","EID":"2-s2.0-85184088628"}]